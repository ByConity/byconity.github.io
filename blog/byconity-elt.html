<!doctype html>
<html lang="en" dir="ltr" class="blog-wrapper blog-post-page plugin-blog plugin-id-default">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.3.1">
<title data-rh="true">Detailed Explanation of ByConity ELT Principles | ByConity</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://byconity.github.io/img/byconity-social-card.png"><meta data-rh="true" name="twitter:image" content="https://byconity.github.io/img/byconity-social-card.png"><meta data-rh="true" property="og:url" content="https://byconity.github.io/blog/byconity-elt"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docusaurus_tag" content="default"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docsearch:docusaurus_tag" content="default"><meta data-rh="true" property="og:title" content="Detailed Explanation of ByConity ELT Principles | ByConity"><meta data-rh="true" name="description" content="Background"><meta data-rh="true" property="og:description" content="Background"><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="article:published_time" content="2023-09-10T00:00:00.000Z"><meta data-rh="true" property="article:author" content="https://github.com/WangTaoTheTonic,https://github.com/tigerwangyb"><meta data-rh="true" property="article:tag" content="video introduction,docusaurus"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://byconity.github.io/blog/byconity-elt"><link data-rh="true" rel="alternate" href="https://byconity.github.io/blog/byconity-elt" hreflang="en"><link data-rh="true" rel="alternate" href="https://byconity.github.io/zh-cn/blog/byconity-elt" hreflang="zh-cn"><link data-rh="true" rel="alternate" href="https://byconity.github.io/blog/byconity-elt" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://Y8UJSN6KEB-dsn.algolia.net" crossorigin="anonymous"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="ByConity RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="ByConity Atom Feed">

<link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-BYY7CCPJZ6"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-BYY7CCPJZ6",{})</script>


<link rel="search" type="application/opensearchdescription+xml" title="ByConity" href="/opensearch.xml"><link rel="stylesheet" href="/assets/css/styles.25c3bd5d.css">
<link rel="preload" href="/assets/js/runtime~main.d9722bb0.js" as="script">
<link rel="preload" href="/assets/js/main.7c81538f.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_Rzz1" href="#docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top navbarHideable_hfek"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.png" alt="ByConity Logo" class="themedImage_DeRy themedImage--light_hbln"><img src="/img/logo.png" alt="ByConity Logo" class="themedImage_DeRy themedImage--dark_qgR1"></div><b class="navbar__title text--truncate">ByConity</b></a><a class="navbar__item navbar__link" href="/docs/introduction/what-is-byconity">Docs</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/blog">Blog</a><a class="navbar__item navbar__link" href="/community/become-maintainer">Community</a><a class="navbar__item navbar__link" href="/users">Users</a></div><div class="navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a class="navbar__link" aria-haspopup="true" aria-expanded="false" role="button" href="/docs/introduction/what-is-byconity">0.4.x</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/docs/introduction/what-is-byconity">0.4.x</a></li><li><a class="dropdown__link" href="/docs/0.3.0/introduction/what-is-byconity">0.3.0</a></li><li><a class="dropdown__link" href="/docs/0.2.0/introduction/main-principle-concepts">0.2.0</a></li></ul></div><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">English</a><ul class="dropdown__menu"><li><a href="/blog/byconity-elt" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang="en">English</a></li><li><a href="/zh-cn/blog/byconity-elt" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="zh-cn">中文（中国）</a></li></ul></div><a href="https://github.com/ByConity/ByConity" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-github-link"><span>GitHub</span></a><div class="searchBox_mmj0"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_NWrx"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_J5VD thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_ZkTY margin-bottom--md">Recent posts</div><ul class="sidebarItemList_Jaez clean-list"><li class="sidebarItem_mMbS"><a aria-current="page" class="sidebarItemLink_LJmi sidebarItemLinkActive_nl4s" href="/blog/byconity-elt">Detailed Explanation of ByConity ELT Principles</a></li><li class="sidebarItem_mMbS"><a class="sidebarItemLink_LJmi" href="/blog/byconity-benchmark">Performance Comparison Analysis of ByConity and Mainstream Open-Source OLAP Engines (ClickHouse, Doris, Presto)</a></li><li class="sidebarItem_mMbS"><a class="sidebarItemLink_LJmi" href="/blog/2023-05-24-byconity-announcement-opensources-its-cloudnative-data-warehouse">ByteDance Open Sources Its Cloud Native Data Warehouse ByConity</a></li><li class="sidebarItem_mMbS"><a class="sidebarItemLink_LJmi" href="/blog/byconity-an-opensource-cloudnative-data-warehouse-post">ByConity -- An Open source Cloud-native Data Warehouse</a></li></ul></nav></aside><main class="col col--7" itemscope="" itemtype="http://schema.org/Blog"><article itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h1 class="title_XMSB" itemprop="headline">Detailed Explanation of ByConity ELT Principles</h1><div class="container_fJtn margin-vert--md"><time datetime="2023-09-10T00:00:00.000Z" itemprop="datePublished">September 10, 2023</time> · <!-- -->10 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_YzU5"><div class="avatar margin-bottom--sm"><a href="https://github.com/WangTaoTheTonic" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="https://github.com/WangTaoTheTonic.png" alt="Tao Wang"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/WangTaoTheTonic" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Tao Wang</span></a></div><small class="avatar__subtitle" itemprop="description">ByConity maintainer</small></div></div></div><div class="col col--6 authorCol_YzU5"><div class="avatar margin-bottom--sm"><a href="https://github.com/tigerwangyb" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="https://github.com/tigerwangyb.png" alt="Yunbo Wang"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/tigerwangyb" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Yunbo Wang</span></a></div><small class="avatar__subtitle" itemprop="description">ByConity maintainer</small></div></div></div></div></header><div id="post-content" class="markdown" itemprop="articleBody"><h2 class="anchor anchorWithHideOnScrollNavbar_l3HI" id="background">Background<a href="#background" class="hash-link" aria-label="Direct link to Background" title="Direct link to Background">​</a></h2><p>When it comes to data warehouses, the use of Extract-Transform-Load (ETL) or Extract-Load-Transform (ELT) is inevitable. It involves extracting data from different sources and in various formats into a data warehouse for processing. Traditionally, the data transformation process uses Extract-Transform-Load (ETL) to convert business data into a data model suitable for data warehouses. However, this relies on an ETL system independent of the data warehouse, resulting in high maintenance costs. As a cloud-native data warehouse, ByConity has gradually supported Extract-Load-Transform (ELT) since version 0.2.0, freeing users from maintaining multiple heterogeneous data systems. This article will introduce ByConity&#x27;s capabilities, implementation principles, and usage methods related to ELT.</p><h2 class="anchor anchorWithHideOnScrollNavbar_l3HI" id="etl-scenarios-and-solutions">ETL Scenarios and Solutions<a href="#etl-scenarios-and-solutions" class="hash-link" aria-label="Direct link to ETL Scenarios and Solutions" title="Direct link to ETL Scenarios and Solutions">​</a></h2><h3 class="anchor anchorWithHideOnScrollNavbar_l3HI" id="differences-between-elt-and-etl">Differences between ELT and ETL<a href="#differences-between-elt-and-etl" class="hash-link" aria-label="Direct link to Differences between ELT and ETL" title="Direct link to Differences between ELT and ETL">​</a></h3><ul><li>ETL: Describes the process of extracting data from a source, transforming it, and loading it into a destination (data warehouse). The Transform phase typically describes the preprocessing of data within the data warehouse.</li></ul><p><img loading="lazy" src="/assets/images/elt1-ccfe04dd9abfa7d620e7c93b024bbc2c.png" width="1080" height="388" class="img_astN"></p><ul><li>ELT focuses on loading minimally processed data into the data warehouse, leaving most of the transformation operations to the analysis phase. Compared to ETL, it requires less data modeling and provides analysts with more flexibility. ELT has become the norm in big data processing today, posing many new requirements for data warehouses.</li></ul><h3 class="anchor anchorWithHideOnScrollNavbar_l3HI" id="challenges-of-resource-duplication">Challenges of Resource Duplication<a href="#challenges-of-resource-duplication" class="hash-link" aria-label="Direct link to Challenges of Resource Duplication" title="Direct link to Challenges of Resource Duplication">​</a></h3><p><img loading="lazy" src="/assets/images/elt2-caa5b7ef03a16466c984978e04735732.png" width="1048" height="402" class="img_astN"></p><p>A typical data pipeline is as follows: We ingest behavioral data, logs, clickstreams, etc., into a storage system using MQ/Kafka/Flink. The storage system can be further divided into on-premises HDFS and cloud-based OSS&amp;S3 remote storage systems. Then, a series of ETL operations are performed on the data warehouse to provide data for OLAP systems for analysis and query. However, some businesses need to branch off from the above storage, exporting data from the overall pipeline at a certain stage of data analysis to perform ETL operations different from the main pipeline, resulting in duplicate data storage. Additionally, two different ETL logics may emerge during this process.</p><p>As the amount of data increases, the cost pressure brought by computational and storage redundancy also increases. Meanwhile, the expansion of storage space makes elastic scaling inconvenient.</p><h3 class="anchor anchorWithHideOnScrollNavbar_l3HI" id="industry-solutions">Industry Solutions<a href="#industry-solutions" class="hash-link" aria-label="Direct link to Industry Solutions" title="Direct link to Industry Solutions">​</a></h3><p>In the industry, there are several approaches to address the above issues:</p><ul><li>Data pre-calculation school: Tools like Kylin. If report generation in Hadoop systems is slow or aggregation capabilities are poor, data pre-calculation can be performed to calculate cubes or views in advance for configured indicators. During actual SQL queries, the cubes or views can be directly used for substitution and returned.</li><li>Streaming and batch integration school: Tools like Flink, Risingwave. Data is aggregated directly in memory for reports or large screens as it flows in. After aggregation, the results are written to HBase or MySQL for retrieval and display. Flink also exposes interfaces for intermediate states, i.e., queryable state, to enable users to better utilize state data. However, the final results still need to be reconciled with batch computation results, and if inconsistencies are found, backtracking operations may be required. The entire process tests the skills of operation and maintenance/development teams.</li><li>Data lake and warehouse integration &amp; HxxP: Combining data lakes with data warehouses.</li></ul><h2 class="anchor anchorWithHideOnScrollNavbar_l3HI" id="elt-in-byconity">ELT in ByConity<a href="#elt-in-byconity" class="hash-link" aria-label="Direct link to ELT in ByConity" title="Direct link to ELT in ByConity">​</a></h2><h3 class="anchor anchorWithHideOnScrollNavbar_l3HI" id="overall-execution-flow">Overall Execution Flow<a href="#overall-execution-flow" class="hash-link" aria-label="Direct link to Overall Execution Flow" title="Direct link to Overall Execution Flow">​</a></h3><p><img loading="lazy" src="/assets/images/elt3-9500640cd18aa26d9bc3357e5dd627c9.png" width="1280" height="828" class="img_astN"></p><h3 class="anchor anchorWithHideOnScrollNavbar_l3HI" id="system-requirements-for-elt-tasks">System Requirements for ELT Tasks:<a href="#system-requirements-for-elt-tasks" class="hash-link" aria-label="Direct link to System Requirements for ELT Tasks:" title="Direct link to System Requirements for ELT Tasks:">​</a></h3><ol><li>Overall scalability: Importing and transforming often require significant resources, and the system needs to scale horizontally to meet rapid data growth.</li><li>Reliability and fault tolerance: Large numbers of jobs can be scheduled orderly; in case of occasional task failures (OOM), container failures, etc., retries can be triggered; able to handle a certain degree of data skewness.</li><li>Efficiency and performance: Effective utilization of multi-core and multi-machine concurrency; fast data import; efficient memory usage (memory management); CPU optimization (vectorization, codegen).</li><li>Ecosystem and observability: Compatible with various tools; task status awareness; task progress awareness; failed log query; certain visualization capabilities.</li></ol><p>Based on the requirements of ELT tasks and the difficulties encountered in current scenarios, ByConity has added the following features and optimizations.</p><h3 class="anchor anchorWithHideOnScrollNavbar_l3HI" id="stage-level-scheduling">Stage-level Scheduling<a href="#stage-level-scheduling" class="hash-link" aria-label="Direct link to Stage-level Scheduling" title="Direct link to Stage-level Scheduling">​</a></h3><p><img loading="lazy" src="/assets/images/elt4-494e04491f26b62b894e7bcea61beb89.png" width="830" height="528" class="img_astN"></p><h4 class="anchor anchorWithHideOnScrollNavbar_l3HI" id="principle-analysis">Principle Analysis<a href="#principle-analysis" class="hash-link" aria-label="Direct link to Principle Analysis" title="Direct link to Principle Analysis">​</a></h4><ul><li>The current SQL execution process in ClickHouse is as follows:<ul><li>In the first stage, the Coordinator receives a distributed table query and converts it into a local table query for each shard node.</li><li>In the second stage, the Coordinator aggregates the results from each node and returns them to the client.</li></ul></li><li>ClickHouse converts the right table in Join operations into a subquery, which brings several issues that are difficult to resolve:<ul><li>Complex queries have multiple subqueries, resulting in high conversion complexity.</li><li>When the Join table is large, it can easily cause OOM in worker nodes.</li><li>Aggregation occurs at the Coordinator, putting pressure on it and easily becoming a performance bottleneck.</li></ul></li></ul><p><img loading="lazy" src="/assets/images/elt5-feb79e6e129f3aeb9ab86aa2b92767f4.png" width="443" height="521" class="img_astN"> <img loading="lazy" src="/assets/images/elt6-8481e54f07ead8899937be2f068395c6.png" width="395" height="536" class="img_astN"> <img loading="lazy" src="/assets/images/elt7-306fde6a5dad86ac0bb435ce6909f7bc.png" width="320" height="231" class="img_astN"></p><p>Unlike ClickHouse, we have implemented optimization for the execution of complex queries in ByConity. By splitting the execution plan, we transform the previous two-stage execution model into stage-level execution. During the logical plan phase, exchange operators are inserted based on operator types. During the execution phase, the entire execution plan is DAG-split based on exchange operators, and scheduling is performed stage by stage. The exchange operators between stages are responsible for data transmission and exchange.
Key nodes:</p><ol><li>Insertion of exchange nodes</li><li>Splitting of stages</li><li>Stage scheduler</li><li>Segment executer</li><li>Exchange manager</li></ol><p><img loading="lazy" src="/assets/images/elt8-91b30f3fc765792bb11ada8747fd2ec2.png" width="583" height="529" class="img_astN"></p><p>Here, we focus on the exchange perspective. As you can see in the figure above, at the top level is the query plan. When converting it to a physical plan, we transform it into different operators based on different data distribution requirements. The source layer, which receives data, is mostly unified and called ExchangeSource. Sinks have different implementations, such as BroadcastSink, Local, PartitionSink, etc., which run as part of map tasks. For cross-node data operations, we use a unified brpc streaming data transmission at the bottom level, and for local operations, we use memory queues. We have made very detailed optimizations for different points:</p><ul><li>Data transmission layer<ul><li>In-process communication uses memory queues, without serialization, zero copy</li><li>Inter-process communication uses brpc stream RPC, ensuring order preservation, connection reuse, status code transmission, compression, etc.</li></ul></li><li>Operator layer<ul><li>Batch sending</li><li>Thread reuse, reducing the number of threads</li></ul></li></ul><h4 class="anchor anchorWithHideOnScrollNavbar_l3HI" id="benefits">Benefits<a href="#benefits" class="hash-link" aria-label="Direct link to Benefits" title="Direct link to Benefits">​</a></h4><p>Because ByConity fully adopts a multi-stage query execution approach, there are significant overall benefits:</p><ul><li>More stable and efficient Coordinator<ul><li>Aggregation and other operators are split to worker nodes for execution</li><li>The Coordinator node only needs to aggregate the final results</li></ul></li><li>Reduced Worker OOM<ul><li>Stage splitting makes each stage&#x27;s computation relatively simple</li><li>The addition of exchange operators reduces memory pressure</li></ul></li><li>More stable and efficient network connections<ul><li>Effective transmission by exchange operators</li><li>Reuse of connection pools</li></ul></li></ul><h3 class="anchor anchorWithHideOnScrollNavbar_l3HI" id="adaptive-scheduler">Adaptive Scheduler<a href="#adaptive-scheduler" class="hash-link" aria-label="Direct link to Adaptive Scheduler" title="Direct link to Adaptive Scheduler">​</a></h3><p>The Adaptive Scheduler is a feature we have implemented for stability. In OLAP scenarios, it may be found that some data is incomplete or data queries timeout, often due to the fact that each worker is shared by all queries. Once a worker is slow, it can affect the execution of the entire query.</p><p><img loading="lazy" src="/assets/images/elt9-5832a9a799604adcf46d919e33a0fd48.png" width="360" height="360" class="img_astN"></p><p>Issues with shared computation nodes:</p><ul><li>The load on the node where Scan occurs is related to the amount of scan data required by different queries, and it cannot be perfectly averaged.</li><li>The resource requirements vary greatly among Plan Segments.
This leads to severe load imbalance among worker nodes. Heavily loaded worker nodes can affect the overall progress of the query. Therefore, we have implemented the following optimization solutions:</li><li>Establishment of a Worker health mechanism. The server side establishes a Worker health management class that can quickly obtain health information about the Worker Group, including CPU, memory, the number of running queries, etc.</li><li>Adaptive scheduling: Each SQL dynamically selects and controls the concurrency of computation nodes based on Worker health.</li></ul><h3 class="anchor anchorWithHideOnScrollNavbar_l3HI" id="query-queue-mechanism">Query Queue Mechanism<a href="#query-queue-mechanism" class="hash-link" aria-label="Direct link to Query Queue Mechanism" title="Direct link to Query Queue Mechanism">​</a></h3><p><img loading="lazy" src="/assets/images/elt10-00e36ff14589366f30019c9a22871ed0.png" width="1280" height="1024" class="img_astN"> <img loading="lazy" src="/assets/images/elt11-7a76adabaa507e6b8502fef8764e9333.png" width="1280" height="1047" class="img_astN"></p><p>Our clusters may also experience full load situations, where all workers are unhealthy or overloaded/overloaded. In such cases, we use a query queue for optimization.
We directly implemented a manager on the server side. Each time a query is made, the manager checks the cluster&#x27;s resources and holds a lock. If resources are insufficient, it waits for resources to be released before waking up the lock. This avoids the server issuing unbounded computation tasks, leading to worker node overloads and crashes.
The current implementation is relatively simple. The server is multi-instanced, and each server instance has its own queue, providing a local perspective lacking a global resource perspective. Additionally, the query status in each queue is not persisted but simply cached in memory.
In the future, we will add coordination between servers to limit query concurrency from a global perspective. We will also persist</p><h3 class="anchor anchorWithHideOnScrollNavbar_l3HI" id="async-execution">Async Execution<a href="#async-execution" class="hash-link" aria-label="Direct link to Async Execution" title="Direct link to Async Execution">​</a></h3><p><img loading="lazy" src="/assets/images/elt12-8734ea2851ceceb9d629659aecd68ac5.png" width="1280" height="708" class="img_astN"></p><p>A typical characteristic of ELT tasks is that their running time is relatively long compared to real-time analysis. Generally, ELT tasks can take minutes or even hours to execute.
Currently, ClickHouse&#x27;s client queries are returned in a blocking manner. This results in the client remaining in a waiting state for an extended period, during which it needs to maintain a connection with the server. In unstable network conditions, the connection between the client and server may be disconnected, leading to task failures on the server side.
To reduce such unnecessary failures and reduce the complexity of maintaining connections for the client, we have developed an asynchronous execution feature, which is implemented as follows:</p><ol><li>User-specified asynchronous execution. Users can specify asynchronous execution on a per-query basis by using <code>settings enable_async_query = 1</code>. Alternatively, they can set it at the session level using <code>set enable_async_query = 1</code>.</li><li>If the query is asynchronous, it is placed in a background thread pool for execution.</li><li>Silent I/O. When an asynchronous query is executing, its interaction with the client, such as log output, needs to be severed.</li></ol><p>Initialization of the query still occurs in the session&#x27;s synchronous thread. Once initialization is complete, the query state is written to the metastore, and an async query ID is returned to the client. The client can use this ID to query the status of the query. After the async query ID is returned, it indicates the completion of the interaction for this query. In this mode, if the statement is a <code>SELECT</code>, subsequent results cannot be sent back to the client. In such cases, we recommend users use a combination of async query and <code>SELECT...INTO OUTFILE</code> to meet their needs.</p><h2 class="anchor anchorWithHideOnScrollNavbar_l3HI" id="future-plans">Future Plans<a href="#future-plans" class="hash-link" aria-label="Direct link to Future Plans" title="Direct link to Future Plans">​</a></h2><p>Regarding ELT mixed loads, the ByConity 0.2.0 version is just the beginning. In subsequent versions, we will continue to optimize query-related capabilities, with ELT as the core focus. The plans are as follows:</p><h3 class="anchor anchorWithHideOnScrollNavbar_l3HI" id="fault-recovery-capabilities">Fault Recovery Capabilities<a href="#fault-recovery-capabilities" class="hash-link" aria-label="Direct link to Fault Recovery Capabilities" title="Direct link to Fault Recovery Capabilities">​</a></h3><ul><li>Operator Spill<ul><li>Spill for Sort, Agg, and Join operators;</li><li>Exchange Spill capability;</li></ul></li><li>Recoverability<ul><li>Operator execution recovery: When ELT tasks run for a long time, occasional failures of intermediate tasks can lead to the failure of the entire query. Supporting task-level retries can significantly reduce occasional failures caused by environmental factors;</li><li>Stage retries: When a node fails, stage-level retries can be performed;</li><li>Ability to save queue job states;</li></ul></li><li>Remote Shuffle Service: Currently, open-source shuffle services in the industry are often tailored for Spark and lack generic clients, such as C++ clients. We will supplement this capability in the future.</li></ul><h3 class="anchor anchorWithHideOnScrollNavbar_l3HI" id="resources">Resources<a href="#resources" class="hash-link" aria-label="Direct link to Resources" title="Direct link to Resources">​</a></h3><ul><li>Specifiable computational resources: Users can specify the computational resources required for a query;</li><li>Computational resource estimation/reservation: Dynamically estimate the computational resources required for a query and allocate them through reservation;</li><li>Dynamic resource allocation: Currently, workers are permanent processes/nodes. Dynamic resource allocation can improve utilization;</li><li>Fine-grained resource isolation: Reduce the mutual influence between queries through worker group or process-level isolation;</li></ul></div><footer class="row docusaurus-mt-lg blogPostFooterDetailsFull_Vbb7"><div class="col"><b>Tags:</b><ul class="tags_HAaO padding--none margin-left--sm"><li class="tag_Ut5_"><a class="tag_sQub tagRegular_dfhI" href="/blog/tags/video-introduction">video introduction</a></li><li class="tag_Ut5_"><a class="tag_sQub tagRegular_dfhI" href="/blog/tags/docusaurus">docusaurus</a></li></ul></div><div class="col margin-top--sm"><a href="https://github.com/ByConity/byconity.github.io/tree/main/blog/2023-09-10-byconity-elt/index.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_O9Og" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Blog post page navigation"><a class="pagination-nav__link pagination-nav__link--next" href="/blog/byconity-benchmark"><div class="pagination-nav__sublabel">Older Post</div><div class="pagination-nav__label">Performance Comparison Analysis of ByConity and Mainstream Open-Source OLAP Engines (ClickHouse, Doris, Presto)</div></a></nav></main><div class="col col--2"><div class="tableOfContents_Q7NC thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#background" class="table-of-contents__link toc-highlight">Background</a></li><li><a href="#etl-scenarios-and-solutions" class="table-of-contents__link toc-highlight">ETL Scenarios and Solutions</a><ul><li><a href="#differences-between-elt-and-etl" class="table-of-contents__link toc-highlight">Differences between ELT and ETL</a></li><li><a href="#challenges-of-resource-duplication" class="table-of-contents__link toc-highlight">Challenges of Resource Duplication</a></li><li><a href="#industry-solutions" class="table-of-contents__link toc-highlight">Industry Solutions</a></li></ul></li><li><a href="#elt-in-byconity" class="table-of-contents__link toc-highlight">ELT in ByConity</a><ul><li><a href="#overall-execution-flow" class="table-of-contents__link toc-highlight">Overall Execution Flow</a></li><li><a href="#system-requirements-for-elt-tasks" class="table-of-contents__link toc-highlight">System Requirements for ELT Tasks:</a></li><li><a href="#stage-level-scheduling" class="table-of-contents__link toc-highlight">Stage-level Scheduling</a></li><li><a href="#adaptive-scheduler" class="table-of-contents__link toc-highlight">Adaptive Scheduler</a></li><li><a href="#query-queue-mechanism" class="table-of-contents__link toc-highlight">Query Queue Mechanism</a></li><li><a href="#async-execution" class="table-of-contents__link toc-highlight">Async Execution</a></li></ul></li><li><a href="#future-plans" class="table-of-contents__link toc-highlight">Future Plans</a><ul><li><a href="#fault-recovery-capabilities" class="table-of-contents__link toc-highlight">Fault Recovery Capabilities</a></li><li><a href="#resources" class="table-of-contents__link toc-highlight">Resources</a></li></ul></li></ul></div></div></div></div></div><footer class="footer footer--dark"><div class="container"><div class="row"><div class="col col--3"><img src="/img/footer-logo.svg" alt="ByConity" class="themedImage_DeRy themedImage--light_hbln footer__logo"><img src="/img/footer-logo.svg" alt="ByConity" class="themedImage_DeRy themedImage--dark_qgR1 footer__logo"></div><div class="col"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/introduction/main-principle-concepts">Docs</a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/community">Community</a></li><li class="footer__item"><a class="footer__link-item" href="/users">Users</a></li><li class="footer__item"><a href="https://space.bilibili.com/2065226922?spm_id_from=333.1007.0.0" target="_blank" rel="noopener noreferrer" class="footer__link-item">Bilibili<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_LBPb"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/blog">Blog</a></li><li class="footer__item"><a href="https://github.com/ByConity/ByConity" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_LBPb"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2023 ByteDance.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.d9722bb0.js"></script>
<script src="/assets/js/main.7c81538f.js"></script>
</body>
</html>