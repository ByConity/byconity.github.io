---
title: Bucket table
tags:
  - Docs
---

# Bucket table Description

When using Bucket table in ByConity, the system will organize the table data according to one or more columns and expressions provided by the user in the table creation statement, and cluster the data with the same value under the same bucket number.

# Benefits of using Bucket table

The following benefits can be obtained on large tables by using cluster key to aggregate data:
1. Checking the cluster key can filter out most of the data, reduce the amount of IO and obtain shorter execution time and higher concurrent QPS
2. The aggregation calculation for cluster key can have less memory usage and shorter execution time, which can be further improved with distributed_perfect_shard optimization
3. The join of two or more tables for the cluster key can be optimized by co-located join, which greatly reduces the amount of shuffle data and results in shorter execution time

# When to consider using Bucket table

1. The table is large enough, which means that the number of parts under a partition needs to be at least significantly more than the number of workers
2. Query statements can benefit from the above benefits

# How to choose a cluster key

The Cluster key can be one or more columns and expressions. It is recommended to use up to 3 fields. More fields usually introduce high write costs and the scope of benefit statements is smaller.

Choosing the correct cluster key has a significant impact on performance, so it needs to be chosen carefully. Generally, the following principles can be followed:
1. Columns that are often used for equality and IN filtering
2. Commonly used aggregation columns
3. Multi-table join key

If the above scenario is commonly used in combination of two columns, such as a = 1 and b = 2, then cluster key can get better results by selecting two columns.

Another dimension to consider is the number of distinct values for a column:
1. The value of distinct needs to exceed at least the number of workers
2. If the number of distinct values is small, it is best to maintain a multiple of the number of workers to achieve a more balanced data distribution during query

# How to choose bucket number

within a partition
1. The data will be allocated to the parts of the corresponding bucket number according to the value of the cluster key
2. Parts of the same bucket number will be sent to the same worker node for calculation during query

Therefore, choosing an appropriate bucket number has a major impact on storage and query, and generally has the following principles:
1. Make sure that the bucket number is a multiple of the number of workers. This is to ensure a balanced allocation during querying. It is generally recommended to set it to 1 or 2 times the number of worker nodes (reserve for expansion of worker node redundancy). The number of worker nodes is sufficient
2. Make sure that there is enough data in a bucket number under a partition, and do not generate too small parts. Therefore, if the table is relatively small, at least ensure that the size of a bucket number part in a partition exceeds 1GB. Do not set too high a bucket nubmer, a bucket number smaller than the number of workers can appear

# How to decide whether to modify the cluster by definition

During operation, due to data changes, query mode changes, and changes in the number of worker nodes, users may want to reset the cluster key and bucket number.

Here you need to consider the cost of implementing the modification, and weigh whether you need to modify and when:
1. To modify the definition of cluster by, it is necessary to perform recluster on the existing existing data, and it is necessary to evaluate the amount of existing data to estimate the execution time of recluster
2. During the recluster period, the query of the existing data will fall back to a normal table, and all the benefits of the bucket table will be temporarily lost
3. Recluster will occupy the resources of the write worker. It is necessary to evaluate whether the current cnch cluster has an independent write worker and the current load, and evaluate the impact on existing tasks such as query and merge

There are two cases here:
1. Modify the cluster key:
   1. At this time, it means that the current data can no longer obtain the income of the bucket table, so there is no need to consider the income lost during recluster
   2. It is necessary to evaluate the impact of the recluster task on existing tasks to determine whether it can be executed
2. Modify the bucket number
   1. The income of the current bucket table is still there, so it is necessary to confirm with the business side the acceptable performance rollback time, further judge whether it can be executed according to the recluster time, and determine the start execution time
   2. It is also necessary to evaluate the impact of the recluster task on existing tasks to determine whether it can be executed