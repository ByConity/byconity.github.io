"use strict";(self.webpackChunkbyconity=self.webpackChunkbyconity||[]).push([[5299],{7407:e=>{e.exports=JSON.parse('{"blogPosts":[{"id":"byconity-elt","metadata":{"permalink":"/zh-cn/blog/byconity-elt","editUrl":"https://github.com/ByConity/byconity.github.io/tree/main/i18n/zh-cn/docusaurus-plugin-content-blog/2023-09-10-byconity-elt/index.md","source":"@site/i18n/zh-cn/docusaurus-plugin-content-blog/2023-09-10-byconity-elt/index.md","title":"ByConity ELT\u539f\u7406\u8be6\u89e3","description":"\u80cc\u666f","date":"2023-09-10T00:00:00.000Z","formattedDate":"2023\u5e749\u670810\u65e5","tags":[{"label":"video introduction","permalink":"/zh-cn/blog/tags/video-introduction"},{"label":"docusaurus","permalink":"/zh-cn/blog/tags/docusaurus"}],"readingTime":14.945,"hasTruncateMarker":false,"authors":[{"name":"Tao Wang","title":"ByConity maintainer","url":"https://github.com/WangTaoTheTonic","imageURL":"https://github.com/WangTaoTheTonic.png","key":"WangTaoTheTonic"},{"name":"Yunbo Wang","title":"ByConity maintainer","url":"https://github.com/tigerwangyb","imageURL":"https://github.com/tigerwangyb.png","key":"tigerwangyb"}],"frontMatter":{"slug":"byconity-elt","title":"ByConity ELT\u539f\u7406\u8be6\u89e3","authors":["WangTaoTheTonic","tigerwangyb"],"tags":["video introduction","docusaurus"]},"nextItem":{"title":"ByteDance Open Sources Its Cloud Native Data Warehouse ByConity","permalink":"/zh-cn/blog/2023-05-24-byconity-announcement-opensources-its-cloudnative-data-warehouse"}},"content":"## \u80cc\u666f\\n\\n\u8c08\u5230\u6570\u636e\u4ed3\u5e93\uff0c \u4e00\u5b9a\u79bb\u4e0d\u5f00\u4f7f\u7528Extract-Transform-Load (ETL)\u6216 Extract-Load-Transform (ELT)\u3002 \u5c06\u6765\u6e90\u4e0d\u540c\u3001\u683c\u5f0f\u5404\u5f02\u7684\u6570\u636e\u63d0\u53d6\u5230\u6570\u636e\u4ed3\u5e93\u4e2d\uff0c\u5e76\u8fdb\u884c\u5904\u7406\u52a0\u5de5\u3002\u4f20\u7edf\u7684\u6570\u636e\u8f6c\u6362\u8fc7\u7a0b\u4e00\u822c\u91c7\u7528Extract-Transform-Load (ETL)\u6765\u5c06\u4e1a\u52a1\u6570\u636e\u8f6c\u6362\u4e3a\u9002\u5408\u6570\u4ed3\u7684\u6570\u636e\u6a21\u578b\uff0c\u7136\u800c\uff0c\u8fd9\u4f9d\u8d56\u4e8e\u72ec\u7acb\u4e8e\u6570\u4ed3\u5916\u7684ETL\u7cfb\u7edf\uff0c\u56e0\u800c\u7ef4\u62a4\u6210\u672c\u8f83\u9ad8\u3002\\nByConity \u4f5c\u4e3a\u4e91\u539f\u751f\u6570\u636e\u4ed3\u5e93\uff0c\u4ece0.2.0\u7248\u672c\u5f00\u59cb\u9010\u6b65\u652f\u6301 Extract-Load-Transform (ELT)\uff0c\u4f7f\u7528\u6237\u514d\u4e8e\u7ef4\u62a4\u591a\u5957\u5f02\u6784\u6570\u636e\u7cfb\u7edf\u3002\u672c\u6587\u5c06\u4ecb\u7ecd ByConity \u5728ELT\u65b9\u9762\u7684\u80fd\u529b\u89c4\u5212\uff0c\u5b9e\u73b0\u539f\u7406\u548c\u4f7f\u7528\u65b9\u5f0f\u7b49\u3002\\n\\n## ETL\u573a\u666f\u548c\u65b9\u6848\\n\\n### ELT\u4e0eETL\u7684\u533a\u522b\\n\\n- ETL\uff1a\u662f\u7528\u6765\u63cf\u8ff0\u5c06\u6570\u636e\u4ece\u6765\u6e90\u7aef\u7ecf\u8fc7\u62bd\u53d6\u3001\u8f6c\u7f6e\u3001\u52a0\u8f7d\u81f3\u76ee\u7684\u7aef\uff08\u6570\u636e\u4ed3\u5e93\uff09\u7684\u8fc7\u7a0b\u3002Transform\u901a\u5e38\u63cf\u8ff0\u5728\u6570\u636e\u4ed3\u5e93\u4e2d\u7684\u524d\u7f6e\u6570\u636e\u52a0\u5de5\u8fc7\u7a0b\u3002\\n\\n![](./elt1.png)\\n\\n- ELT \u4e13\u6ce8\u4e8e\u5c06\u6700\u5c0f\u5904\u7406\u7684\u6570\u636e\u52a0\u8f7d\u5230\u6570\u636e\u4ed3\u5e93\u4e2d\uff0c\u800c\u628a\u5927\u90e8\u5206\u7684\u8f6c\u6362\u64cd\u4f5c\u7559\u7ed9\u5206\u6790\u9636\u6bb5\u3002\u76f8\u6bd4\u8d77\u524d\u8005\uff08ETL)\uff0c\u5b83\u4e0d\u9700\u8981\u8fc7\u591a\u7684\u6570\u636e\u5efa\u6a21\uff0c\u800c\u7ed9\u5206\u6790\u8005\u63d0\u4f9b\u66f4\u7075\u6d3b\u7684\u9009\u9879\u3002ELT\u5df2\u7ecf\u6210\u4e3a\u5f53\u4eca\u5927\u6570\u636e\u7684\u5904\u7406\u5e38\u6001\uff0c\u5b83\u5bf9\u6570\u636e\u4ed3\u5e93\u4e5f\u63d0\u51fa\u4e86\u5f88\u591a\u65b0\u7684\u8981\u6c42\u3002\\n\\n### \u8d44\u6e90\u91cd\u590d\u7684\u6311\u6218\\n\\n![](./elt2.png)\\n\\n\u5178\u578b\u7684\u6570\u636e\u94fe\u8def\u5982\u4e0b\uff1a\u6211\u4eec\u5c06\u884c\u4e3a\u6570\u636e\u3001\u65e5\u5fd7\u3001\u70b9\u51fb\u6d41\u7b49\u901a\u8fc7MQ/ Kafka/ Flink\u5c06\u5176\u63a5\u5165\u5b58\u50a8\u7cfb\u7edf\u5f53\u4e2d\uff0c\u5b58\u50a8\u7cfb\u7edf\u53c8\u53ef\u5206\u4e3a\u57df\u5185\u7684HDFS \u548c\u4e91\u4e0a\u7684 OSS& S3 \u8fd9\u79cd\u8fdc\u7a0b\u50a8\u5b58\u7cfb\u7edf\uff0c\u7136\u540e\u8fdb\u884c\u4e00\u7cfb\u5217\u7684\u6570\u4ed3\u7684ETL\u64cd\u4f5c\uff0c\u63d0\u4f9b\u7ed9 OLAP\u7cfb\u7edf\u5b8c\u6210\u5206\u6790\u67e5\u8be2\u3002\\n\u4f46\u6709\u4e9b\u4e1a\u52a1\u9700\u8981\u4ece\u4e0a\u8ff0\u7684\u5b58\u50a8\u4e2d\u505a\u4e00\u4e2a\u5206\u652f\uff0c\u56e0\u6b64\u4f1a\u5728\u6570\u636e\u5206\u6790\u7684\u67d0\u4e00\u9636\u6bb5\uff0c\u4ece\u6574\u4f53\u94fe\u8def\u4e2d\u5c06\u6570\u636e\u5bfc\u51fa\uff0c\u505a\u4e00\u4e9b\u4e0d\u540c\u4e8e\u4e3b\u94fe\u8def\u7684ETL\u64cd\u4f5c\uff0c\u4f1a\u51fa\u73b0\u4e24\u4efd\u6570\u636e\u5b58\u50a8\u3002\u5176\u6b21\u5728\u8fd9\u8fc7\u7a0b\u4e2d\u4e5f\u4f1a\u51fa\u73b0\u4e24\u5957\u4e0d\u540c\u7684ETL\u903b\u8f91\u3002\\n\u5f53\u6570\u636e\u91cf\u53d8\u5927\uff0c\u8ba1\u7b97\u5197\u4f59\u4ee5\u53ca\u5b58\u50a8\u5197\u4f59\u6240\u5e26\u6765\u7684\u6210\u672c\u538b\u529b\u4e5f\u4f1a\u6108\u53d1\u53d8\u5927\uff0c\u540c\u65f6\uff0c\u5b58\u50a8\u7a7a\u95f4\u7684\u81a8\u80c0\u4e5f\u4f1a\u8ba9\u5f39\u6027\u6269\u5bb9\u53d8\u5f97\u4e0d\u4fbf\u5229\u3002\\n\\n### \u4e1a\u754c\u89e3\u51b3\u601d\u8def\\n\\n\u5728\u4e1a\u754c\u4e2d\uff0c\u4e3a\u4e86\u89e3\u51b3\u4ee5\u4e0a\u95ee\u9898\uff0c\u6709\u4ee5\u4e0b\u51e0\u7c7b\u6d41\u6d3e\uff1a\\n- \u6570\u636e\u9884\u8ba1\u7b97\u6d41\u6d3e\uff1a\u5982Kylin\u7b49\u3002\u5982\u679cHadoop\u7cfb\u7edf\u4e2d\u51fa\u62a5\u8868\u8f83\u6162\u6216\u805a\u5408\u80fd\u529b\u8f83\u5dee\uff0c\u53ef\u4ee5\u53bb\u505a\u4e00\u4e2a\u6570\u636e\u7684\u9884\u8ba1\u7b97\uff0c\u63d0\u524d\u5c06\u914d\u7684\u6307\u6807\u7684cube\u6216\u4e00\u4e9b\u89c6\u56fe\u7b97\u597d\u3002\u5b9e\u9645SQL\u67e5\u8be2\u65f6\uff0c\u53ef\u4ee5\u76f4\u63a5\u7528\u91cc\u9762\u7684cube\u6216\u89c6\u56fe\u505a\u66ff\u6362\uff0c\u4e4b\u540e\u76f4\u63a5\u8fd4\u56de\u3002\\n- \u6d41\u6279\u4e00\u4f53\u6d3e\uff1a\u5982 Flink\u3001Risingwave\u3002\u5728\u6570\u636e\u6d41\u8fdb\u65f6\uff0c\u9488\u5bf9\u4e00\u4e9b\u9700\u8981\u51fa\u62a5\u8868\u6216\u8005\u9700\u8981\u505a\u5927\u5c4f\u7684\u6570\u636e\u76f4\u63a5\u5185\u5b58\u4e2d\u505a\u805a\u5408\u3002\u805a\u5408\u5b8c\u6210\u540e\uff0c\u5c06\u7ed3\u679c\u5199\u5165HBase\u6216MySQL\u4e2d\u518d\u53bb\u53d6\u6570\u636e\uff0c\u5c06\u6570\u636e\u53d6\u51fa\u540e\u4f5c\u5c55\u793a\u3002Flink\u8fd8\u4f1a\u53bb\u76f4\u63a5\u66b4\u9732\u4e2d\u95f4\u72b6\u6001\u7684\u63a5\u53e3\uff0c\u5373queryable state\uff0c\u8ba9\u7528\u6237\u66f4\u597d\u7684\u4f7f\u7528\u72b6\u6001\u6570\u636e\u3002\u4f46\u662f\u6700\u540e\u8fd8\u4f1a\u4e0e\u6279\u8ba1\u7b97\u7684\u7ed3\u679c\u5b8c\u6210\u5bf9\u6570\uff0c\u5982\u679c\u4e0d\u4e00\u81f4\uff0c\u9700\u8981\u8fdb\u884c\u56de\u67e5\u64cd\u4f5c\uff0c\u6574\u4e2a\u8fc7\u7a0b\u8003\u9a8c\u8fd0\u7ef4/\u5f00\u53d1\u540c\u5b66\u7684\u529f\u529b\u3002\\n- \u6e56\u4ed3\u4e00\u4f53&HxxP:\u5c06\u6570\u636e\u6e56\u4e0e\u6570\u636e\u4ed3\u5e93\u7ed3\u5408\u8d77\u6765\u3002\\n\\n\\n## ELT in ByConity\\n\\n### \u6574\u4f53\u6267\u884c\u6d41\u7a0b\\n\\n![](./elt3.png)\\n\\n### ELT\u4efb\u52a1\u5bf9\u7cfb\u7edf\u7684\u8981\u6c42\uff1a\\n\\n1. \u6574\u4f53\u6613\u6269\u5c55\uff1a\u5bfc\u5165\u548c\u8f6c\u6362\u901a\u5e38\u9700\u8981\u5927\u91cf\u7684\u8d44\u6e90\uff0c\u7cfb\u7edf\u9700\u8981\u901a\u8fc7\u6c34\u5e73\u6269\u5c55\u7684\u65b9\u5f0f\u6765\u6ee1\u8db3\u6570\u636e\u91cf\u7684\u5feb\u901f\u589e\u957f\u3002\\n2. \u53ef\u9760\u6027\u548c\u5bb9\u9519\u80fd\u529b\uff1a\u5927\u91cf\u7684job\u80fd\u6709\u5e8f\u8c03\u5ea6\uff1b\u51fa\u73b0task\u5076\u7136\u5931\u8d25\uff08OOM\uff09\u3001container\u5931\u8d25\u65f6\uff0c\u80fd\u591f\u62c9\u8d77\u91cd\u8bd5\uff1b\u80fd\u5904\u7406\u4e00\u5b9a\u7684\u6570\u636e\u503e\u659c\\n3. \u6548\u7387&\u6027\u80fd\uff1a\u6709\u6548\u5229\u7528\u591a\u6838\u591a\u673a\u5e76\u53d1\u80fd\u529b\uff1b\u6570\u636e\u5feb\u901f\u5bfc\u5165\uff1b\u5185\u5b58\u4f7f\u7528\u6709\u6548\uff08\u5185\u5b58\u7ba1\u7406\uff09\uff1bCPU\u4f18\u5316\uff08\u5411\u91cf\u5316\u3001codegen\uff09\\n4. \u751f\u6001&\u53ef\u89c2\u6d4b\u6027\uff1a\u53ef\u5bf9\u63a5\u591a\u79cd\u5de5\u5177\uff1b\u4efb\u52a1\u72b6\u6001\u611f\u77e5\uff1b\u4efb\u52a1\u8fdb\u5ea6\u611f\u77e5\uff1b\u5931\u8d25\u65e5\u5fd7\u67e5\u8be2\uff1b\u6709\u4e00\u5b9a\u53ef\u89c6\u5316\u80fd\u529b\\n\\nByConity \u9488\u5bf9ELT\u4efb\u52a1\u7684\u8981\u6c42\uff0c\u4ee5\u53ca\u5f53\u524d\u573a\u666f\u9047\u5230\u7684\u56f0\u96be\uff0c\u65b0\u589e\u4e86\u4ee5\u4e0b\u7279\u6027\u548c\u4f18\u5316\u6539\u8fdb\u3002\\n\\n### \u5206\u9636\u6bb5\u6267\u884c\uff08Stage-level Scheduling\uff09\\n![](./elt4.png)\\n\\n#### \u539f\u7406\u89e3\u6790\\n- \u5f53\u524d ClickHouse\u7684 SQL \u6267\u884c\u8fc7\u7a0b\u5982\u4e0b\uff1a\\n  - \u7b2c\u4e00\u9636\u6bb5\uff0cCoordinator \u6536\u5230\u5206\u5e03\u5f0f\u8868\u67e5\u8be2\u540e\u5c06\u8bf7\u6c42\u8f6c\u6362\u4e3a\u5bf9 local \u8868\u67e5\u8be2\u53d1\u9001\u7ed9\u6bcf\u4e2a shard \u8282\u70b9\uff1b\\n  - \u7b2c\u4e8c\u9636\u6bb5\uff0cCoordinator \u6536\u5230\u5404\u4e2a\u8282\u70b9\u7684\u7ed3\u679c\u540e\u6c47\u805a\u8d77\u6765\u5904\u7406\u540e\u8fd4\u56de\u7ed9\u5ba2\u6237\u7aef\uff1b\\n- ClickHouse \u5c06Join\u64cd\u4f5c\u4e2d\u7684\u53f3\u8868\u8f6c\u6362\u4e3a\u5b50\u67e5\u8be2\uff0c\u5e26\u6765\u5982\u4e0b\u51e0\u4e2a\u95ee\u9898\u90fd\u5f88\u96be\u4ee5\u89e3\u51b3\uff1a\\n  - \u590d\u6742\u7684query\u6709\u591a\u4e2a\u5b50\u67e5\u8be2\uff0c\u8f6c\u6362\u590d\u6742\u5ea6\u9ad8\uff1b\\n  - Join\u8868\u8f83\u5927\u65f6\uff0c\u5bb9\u6613\u9020\u6210worker\u8282\u70b9\u7684OOM\uff1b\\n  - \u805a\u5408\u9636\u6bb5\u5728Cooridnator\uff0c\u538b\u529b\u5927\uff0c\u5bb9\u6613\u6210\u4e3a\u6027\u80fd\u74f6\u9888\uff1b\\n\\n![](./elt5.png) ![](./elt6.png) ![](./elt7.png)\\n\\n\u4e0d\u540c\u4e8eClickHouse\uff0c\u6211\u4eec\u5728ByConity \u4e2d\u5b9e\u73b0\u4e86\u5bf9\u590d\u6742\u67e5\u8be2\u7684\u6267\u884c\u4f18\u5316\u3002\u901a\u8fc7\u5bf9\u6267\u884c\u8ba1\u5212\u7684\u5207\u5206\uff0c\u5c06\u4e4b\u524d\u7684\u4e24\u9636\u6bb5\u6267\u884c\u6a21\u578b\u8f6c\u6362\u4e3a\u5206\u9636\u6bb5\u6267\u884c\u3002\u5728\u903b\u8f91\u8ba1\u5212\u9636\u6bb5\uff0c\u6839\u636e\u7b97\u5b50\u7c7b\u578b\u63d2\u5165exchange\u7b97\u5b50\u3002\u6267\u884c\u9636\u6bb5\u6839\u636eexchange\u7b97\u5b50\u5c06\u6574\u4e2a\u6267\u884c\u8ba1\u5212\u8fdb\u884cDAG\u5207\u5206\uff0c\u5e76\u4e14\u5206stage\u8fdb\u884c\u8c03\u5ea6\u3002stage\u4e4b\u95f4\u7684exchange\u7b97\u5b50\u8d1f\u8d23\u5b8c\u6210\u6570\u636e\u4f20\u8f93\u548c\u4ea4\u6362\u3002\\n\u5173\u952e\u8282\u70b9\uff1a\\n1. exchange\u8282\u70b9\u63d2\u5165\\n2. \u5207\u5206stage\\n3. stage scheduler\\n4. segment executer\\n5. exchange manager\\n\\n![](./elt8.png)\\n\\n\u8fd9\u91cc\u91cd\u70b9\u6765\u8bb2\u4e00\u4e0bexchange\u7684\u89c6\u7ebf\u3002\u4e0a\u56fe\u53ef\u4ee5\u770b\u5230\uff0c\u6700\u9876\u5c42\u7684\u662fquery plan\u3002\u4e0b\u9762\u8f6c\u6362\u6210\u7269\u7406\u8ba1\u5212\u7684\u65f6\u5019\uff0c\u6211\u4eec\u4f1a\u6839\u636e\u4e0d\u540c\u7684\u6570\u636e\u5206\u5e03\u7684\u8981\u6c42\u8f6c\u6362\u6210\u4e0d\u540c\u7684\u7b97\u5b50\u3002source\u5c42\u662f\u63a5\u6536\u6570\u636e\u7684\u8282\u70b9\uff0c\u57fa\u672c\u90fd\u662f\u7edf\u4e00\u7684\uff0c\u53eb\u505aExchangeSource\u3002Sink\u5219\u6709\u4e0d\u540c\u7684\u5b9e\u73b0\uff0cBroadcastSink\u3001Local\u3001PartitionSink\u7b49\uff0c\u4ed6\u4eec\u662f\u4f5c\u4e3amap task\u7684\u4e00\u90e8\u5206\u53bb\u8fd0\u884c\u7684\u3002\u5982\u679c\u662f\u8de8\u8282\u70b9\u7684\u6570\u636e\u64cd\u4f5c\uff0c\u6211\u4eec\u5728\u5e95\u5c42\u4f7f\u7528\u7edf\u4e00\u7684brpc\u6d41\u5f0f\u6570\u636e\u4f20\u8f93\uff0c\u5982\u679c\u662f\u672c\u5730\uff0c\u5219\u4f7f\u7528\u5185\u5b58\u961f\u5217\u6765\u5b9e\u73b0\u3002\u9488\u5bf9\u4e0d\u540c\u7684\u70b9\uff0c\u6211\u4eec\u8fdb\u884c\u4e86\u975e\u5e38\u7ec6\u81f4\u7684\u4f18\u5316\uff1a\\n- \u6570\u636e\u4f20\u8f93\u5c42\\n  - \u8fdb\u7a0b\u5185\u901a\u8fc7\u5185\u5b58\u961f\u5217\uff0c\u65e0\u5e8f\u5217\u5316\uff0czero copy\\n  - \u8fdb\u7a0b\u95f4\u4f7f\u7528brpc stream rpc\uff0c\u4fdd\u5e8f\u3001\u8fde\u63a5\u590d\u7528\u3001\u72b6\u6001\u7801\u4f20\u8f93\u3001\u538b\u7f29\u7b49\\n- \u7b97\u5b50\u5c42\\n  - \u6279\u91cf\u53d1\u9001\\n  - \u7ebf\u7a0b\u590d\u7528\uff0c\u51cf\u5c11\u7ebf\u7a0b\u6570\u91cf\\n\\n#### \u5e26\u6765\u7684\u6536\u76ca\\n\\n\u56e0\u4e3aByConity \u5f7b\u5e95\u91c7\u7528\u4e86\u591a\u9636\u6bb5\u7684\u67e5\u8be2\u6267\u884c\u65b9\u5f0f\uff0c\u6574\u4f53\u6709\u5f88\u5927\u7684\u6536\u76ca\uff1a\\n- Cooridnator\u66f4\u7a33\u5b9a\u3001\u66f4\u9ad8\u6548\\n  - \u805a\u5408\u7b49\u7b97\u5b50\u62c6\u5206\u5230worker\u8282\u70b9\u6267\u884c\\n  - Cooridnator\u8282\u70b9\u53ea\u9700\u8981\u805a\u5408\u6700\u7ec8\u7ed3\u679c\\n- Worker OOM\u51cf\u5c11\\n  - \u8fdb\u884c\u4e86stage\u5207\u5206\uff0c\u6bcf\u4e2astage\u7684\u8ba1\u7b97\u76f8\u5bf9\u7b80\u5355\\n  - \u589e\u52a0\u4e86exchange\u7b97\u5b50\uff0c\u51cf\u5c11\u5185\u5b58\u538b\u529b\\n- \u7f51\u7edc\u8fde\u63a5\u66f4\u52a0\u7a33\u5b9a\u3001\u9ad8\u6548\\n  - exchange\u7b97\u5b50\u6709\u6548\u4f20\u8f93\\n  - \u590d\u7528\u8fde\u63a5\u6c60\\n\\n### \u81ea\u9002\u5e94\u7684\u8c03\u5ea6\u5668\uff08Adaptive Scheduler\uff09\\n\\nAdaptive Scheduler \u5c5e\u4e8e\u6211\u4eec\u5728\u7a33\u5b9a\u6027\u65b9\u9762\u6240\u505a\u7684\u7279\u6027\u3002\u5728OLAP\u573a\u666f\u4e2d\u53ef\u80fd\u4f1a\u53d1\u73b0\u90e8\u5206\u6570\u636e\u4e0d\u5168\u6216\u6570\u636e\u67e5\u8be2\u8d85\u65f6\u7b49\uff0c\u539f\u56e0\u662f\u6bcf\u4e2aworker\u662f\u6240\u6709\u7684query\u5171\u7528\u7684\uff0c\u8fd9\u6837\u4e00\u65e6\u6709\u4e00\u4e2aworker \u8f83\u6162\u5c31\u4f1a\u5bfc\u81f4\u6574\u4e2aquery\u7684\u6267\u884c\u53d7\u5230\u5f71\u54cd\u3002\\n\\n![](./elt9.png)\\n\\n\u8ba1\u7b97\u8282\u70b9\u5171\u7528\u5b58\u5728\u7684\u95ee\u9898\uff1a\\n- Scan \u6240\u5728\u7684\u8282\u70b9\u8d1f\u8f7d\u548c\u4e0d\u540c\u67e5\u8be2\u6240\u9700\u7684\u626b\u63cf\u6570\u636e\u91cf\u76f8\u5173\uff0c\u505a\u4e0d\u5230\u5b8c\u5168\u5e73\u5747\uff1b\\n- \u5404 Plan Segment \u6240\u9700\u8d44\u6e90\u5dee\u5f02\u5927\uff1b\\n\u8fd9\u5c31\u5bfc\u81f4worker\u8282\u70b9\u4e4b\u95f4\u7684\u8d1f\u8f7d\u4e25\u91cd\u4e0d\u5747\u8861\u3002\u8d1f\u8f7d\u8f83\u91cd\u7684worker\u8282\u70b9\u5c31\u4f1a\u5f71\u54cdquery\u6574\u4f53\u7684\u8fdb\u7a0b\u3002\u56e0\u6b64\u6211\u4eec\u505a\u4e86\u4ee5\u4e0b\u7684\u4f18\u5316\u65b9\u6848\uff1a\\n- \u5efa\u7acb Worker \u5065\u5eb7\u5ea6\u673a\u5236\u3002Server \u7aef\u5efa\u7acb Worker \u5065\u5eb7\u5ea6\u7ba1\u7406\u7c7b\uff0c\u53ef\u4ee5\u5feb\u901f\u83b7\u53d6 Worker Group \u7684\u5065\u5eb7\u5ea6\u4fe1\u606f\uff0c\u5305\u62ecCPU\u3001\u5185\u5b58\u3001\u8fd0\u884cQuery\u6570\u91cf\u7b49\u4fe1\u606f\u3002\\n- \u81ea\u9002\u5e94\u8c03\u5ea6\uff1a\u6bcf\u4e2aSQL \u6839\u636e Worker \u5065\u5eb7\u5ea6\u52a8\u6001\u7684\u8fdb\u884c\u9009\u62e9\u4ee5\u53ca\u8ba1\u7b97\u8282\u70b9\u5e76\u53d1\u5ea6\u63a7\u5236\u3002\\n\\n### \u67e5\u8be2\u7684\u961f\u5217\u673a\u5236\uff08Query Queue\uff09\\n\\n![](./elt10.png) ![](./elt11.png)\\n\\n\u6211\u4eec\u7684\u96c6\u7fa4\u4e5f\u4f1a\u51fa\u73b0\u6ee1\u8f7d\u60c5\u51b5\uff0c\u5373\u6240\u6709\u7684worker\u90fd\u662f\u4e0d\u5065\u5eb7\u7684\u6216\u8005\u6ee1\u8f7d/\u8d85\u8f7d\u7684\uff0c\u5c31\u4f1a\u7528\u67e5\u8be2\u961f\u5217\u6765\u8fdb\u884c\u4f18\u5316\u3002\\n\u6211\u4eec\u76f4\u63a5\u5728server\u7aef\u505a\u4e86\u4e00\u4e2amanager\u3002\u6bcf\u6b21\u67e5\u8be2\u7684\u65f6\u5019manager\u4f1a\u53bbcheck\u96c6\u7fa4\u7684\u8d44\u6e90\uff0c\u5e76\u4e14\u6301\u6709\u4e00\u4e2a\u9501\u3002\u5982\u679c\u8d44\u6e90\u4e0d\u591f\u7528\uff0c\u5219\u7b49\u5f85\u8d44\u6e90\u91ca\u653e\u540e\u53bb\u5524\u9192\u8fd9\u4e2a\u9501\u3002\u8fd9\u5c31\u907f\u514d\u4e86Server\u7aef\u4e0d\u9650\u5236\u7684\u4e0b\u53d1\u8ba1\u7b97\u4efb\u52a1\uff0c\u5bfc\u81f4worker\u8282\u70b9\u8d85\u8f7d\uff0c\u7136\u540e\u5d29\u6389\u7684\u60c5\u51b5\u3002\\n\u5f53\u524d\u5b9e\u73b0\u76f8\u5bf9\u7b80\u5355\u3002server\u662f\u591a\u5b9e\u4f8b\uff0c\u6bcf\u4e2aserver\u5b9e\u4f8b\u4e2d\u90fd\u6709queue\uff0c\u6240\u6301\u6709\u7684\u662f\u4e00\u4e2a\u5c40\u90e8\u89c6\u89d2\uff0c\u7f3a\u4e4f\u5168\u5c40\u7684\u8d44\u6e90\u89c6\u89d2\u3002\u9664\u6b64\u4e4b\u5916\uff0c\u6bcf\u4e2aqueue\u4e2d\u7684\u67e5\u8be2\u72b6\u6001\u6ca1\u6709\u6301\u4e45\u5316\uff0c\u53ea\u662f\u7b80\u5355\u7684\u7f13\u5b58\u5728\u5185\u5b58\u4e2d\u3002\\n\u540e\u7eed\uff0c\u6211\u4eec\u4f1a\u589e\u52a0server\u4e4b\u95f4\u7684\u534f\u8c03\uff0c\u5728\u4e00\u4e2a\u5168\u5c40\u7684\u89c6\u89d2\u4e0a\u5bf9\u67e5\u8be2\u5e76\u53d1\u505a\u9650\u5236\u3002\u4e5f\u4f1a\u5bf9server\u5b9e\u4f8b\u4e2dquery\u505a\u6301\u4e45\u5316\uff0c\u589e\u52a0\u4e00\u4e9bfailover\u7684\u573a\u666f\u652f\u6301\u3002\\n\\n### \u5f02\u6b65\u6267\u884c\uff08Async Execution\uff09\\n\\n![](./elt12.png)\\n\\nELT\u4efb\u52a1\u7684\u4e00\u4e2a\u5178\u578b\u7279\u5f81\u5c31\u662f\uff1a\u76f8\u5bf9\u4e8e\u5373\u65f6\u5206\u6790\uff0c\u4ed6\u4eec\u7684\u8fd0\u884c\u65f6\u95f4\u4f1a\u76f8\u5bf9\u8f83\u957f\u3002\u4e00\u822cELT\u4efb\u52a1\u6267\u884c\u65f6\u957f\u4e3a\u5206\u949f\u7ea7\uff0c\u751a\u81f3\u5230\u8fbe\u5c0f\u65f6\u7ea7\u3002\\n\u76ee\u524d ClickHouse\u7684\u5ba2\u6237\u7aef\u67e5\u8be2\u90fd\u91c7\u7528\u963b\u585e\u7684\u65b9\u5f0f\u8fdb\u884c\u8fd4\u56de\u3002\u8fd9\u6837\u5c31\u9020\u6210\u4e86\u5ba2\u6237\u7aef\u957f\u671f\u5904\u4e8e\u7b49\u5f85\u7684\u60c5\u51b5\uff0c\u800c\u5728\u8fd9\u4e2a\u7b49\u5f85\u8fc7\u7a0b\u4e2d\u8fd8\u9700\u8981\u4fdd\u6301\u548c\u670d\u52a1\u7aef\u7684\u8fde\u63a5\u3002\u5728\u4e0d\u7a33\u5b9a\u7684\u7f51\u7edc\u60c5\u51b5\u4e0b\uff0c\u5ba2\u6237\u7aef\u548c\u670d\u52a1\u7aef\u7684\u8fde\u63a5\u4f1a\u65ad\u5f00\uff0c\u4ece\u800c\u5bfc\u81f4\u670d\u52a1\u7aef\u7684\u4efb\u52a1\u5931\u8d25\u3002\\n\u4e3a\u4e86\u51cf\u5c11\u8fd9\u79cd\u4e0d\u5fc5\u8981\u7684\u5931\u8d25\uff0c\u4ee5\u53ca\u51cf\u5c11\u5ba2\u6237\u7aef\u4e3a\u4e86\u7ef4\u6301\u8fde\u63a5\u7684\u589e\u52a0\u7684\u590d\u6742\u5ea6\u3002\u6211\u4eec\u5f00\u53d1\u4e86\u5f02\u6b65\u6267\u884c\u7684\u529f\u80fd\uff0c\u5b83\u7684\u5b9e\u73b0\u5982\u4e0b\uff1a\\n\\n1. \u7528\u6237\u6307\u5b9a\u5f02\u6b65\u6267\u884c\u3002\u7528\u6237\u53ef\u4ee5\u901a\u8fc7settings enable_async_query = 1\u7684\u65b9\u5f0f\u8fdb\u884cper query\u7684\u6307\u5b9a\u3002\u4e5f\u53ef\u4ee5\u901a\u8fc7set enable_async_query = 1\u7684\u65b9\u5f0f\u8fdb\u884csession\u7ea7\u522b\u7684\u6307\u5b9a\u3002\\n2. \u5982\u679c\u662f\u5f02\u6b65query\uff0c\u5219\u5c06\u5176\u653e\u5230\u540e\u53f0\u7ebf\u7a0b\u6c60\u4e2d\u8fd0\u884c\\n3. \u9759\u9ed8io\u3002\u5f53\u5f02\u6b65query\u6267\u884c\u65f6\uff0c\u5219\u9700\u8981\u5207\u65ad\u5b83\u548c\u5ba2\u6237\u7aef\u7684\u4ea4\u4e92\u903b\u8f91\uff0c\u6bd4\u5982\u8f93\u51fa\u65e5\u5fd7\u7b49\u3002\\n\\n\u9488\u5bf9query\u7684\u521d\u59cb\u5316\u8fd8\u662f\u5728session\u7684\u540c\u6b65\u7ebf\u7a0b\u4e2d\u8fdb\u884c\u3002\u4e00\u65e6\u5b8c\u6210\u521d\u59cb\u5316\uff0c\u5219\u5c06query\u72b6\u6001\u5199\u5165\u5230metastore\uff0c\u5e76\u5411\u5ba2\u6237\u7aef\u8fd4\u56deasync query id\u3002\u5ba2\u6237\u7aef\u53ef\u4ee5\u7528\u8fd9\u4e2aid\u67e5\u8be2query\u7684\u72b6\u6001\u3002async query id\u8fd4\u56de\u540e\uff0c\u5219\u8868\u793a\u5b8c\u6210\u6b64\u6b21\u67e5\u8be2\u7684\u4ea4\u4e92\u3002\u8fd9\u79cd\u6a21\u5f0f\u4e0b\uff0c\u5982\u679c\u8bed\u53e5\u662fselect\uff0c\u90a3\u4e48\u540e\u7eed\u7ed3\u679c\u5219\u65e0\u6cd5\u56de\u4f20\u7ed9\u5ba2\u6237\u7aef\u3002\u8fd9\u79cd\u60c5\u51b5\u4e0b\u6211\u4eec\u63a8\u8350\u7528\u6237\u4f7f\u7528async query + select...into outfile\u7684\u7ec4\u5408\u6765\u6ee1\u8db3\u9700\u6c42\u3002\\n\\n## \u672a\u6765\u89c4\u5212\\n\\n\u9488\u5bf9ELT\u6df7\u5408\u8d1f\u8f7d\uff0cByConity 0.2.0\u7248\u672c\u76ee\u524d\u53ea\u662f\u725b\u5200\u5c0f\u8bd5\u3002\u540e\u7eed\u7684\u7248\u672c\u4e2d\u6211\u4eec\u4f1a\u6301\u7eed\u4f18\u5316\u67e5\u8be2\u76f8\u5173\u7684\u80fd\u529b\uff0cELT\u4e3a\u6838\u5fc3\u7684\u89c4\u5212\u5982\u4e0b\uff1a\\n\\n### \u6545\u969c\u6062\u590d\u80fd\u529b\\n\\n- \u7b97\u5b50Spill\\n  - Sort\u3001Agg\u3001Join \u7b97\u5b50Spill\uff1b\\n  - Exchange Spill \u80fd\u529b\uff1b\\n- Recoverability \u5bb9\u9519\u6062\u590d\\n  - \u7b97\u5b50\u6267\u884c\u6062\u590d\uff1aELT\u4efb\u52a1\u8fd0\u884c\u65f6\u957f\u8f83\u957f\u65f6\uff0c\u4e2d\u95f4 Task\u7684\u5076\u53d1\u5931\u8d25\u4f1a\u5bfc\u81f4\u6574\u4e2aQuery\u5931\u8d25\uff0c\u652f\u6301Task \u7ea7\u522b\u91cd\u8bd5\u53ef\u4ee5\u6781\u5927\u5730\u964d\u4f4e\u73af\u5883\u539f\u56e0\u5bfc\u81f4\u7684\u5076\u53d1\u5931\u8d25\uff1b\\n  - Stage\u91cd\u8bd5\uff1a\u5f53\u8282\u70b9\u5931\u8d25\u65f6\uff0c\u53ef\u4ee5\u8fdb\u884c Stage\u7ea7\u522b\u7684\u91cd\u8bd5\uff1b\\n  - \u4fdd\u5b58\u961f\u5217\u4f5c\u4e1a\u72b6\u6001\u7684\u80fd\u529b\uff1b\\n- Remote Shuffle Service\uff1a\u5f53\u524d\u4e1a\u754c\u5f00\u6e90\u7684 shuffle service\u901a\u5e38\u4e3aSpark\u5b9a\u5236\uff0c\u6ca1\u6709\u901a\u7528\u7684\u5ba2\u6237\u7aef\uff0c\u6bd4\u5982c++\u5ba2\u6237\u7aef\u3002\u540e\u7eed\u6211\u4eec\u4f1a\u8865\u5145\u8fd9\u90e8\u5206\u80fd\u529b\u3002\\n\\n### \u8d44\u6e90\\n\\n- \u8ba1\u7b97\u8d44\u6e90\u53ef\u6307\u5b9a\uff1a\u7528\u6237\u53ef\u6307\u5b9aquery\u9700\u8981\u7684\u8ba1\u7b97\u8d44\u6e90\uff1b\\n- \u8ba1\u7b97\u8d44\u6e90\u9884\u4f30/\u9884\u5360\uff1a\u53ef\u52a8\u6001\u9884\u4f30query\u9700\u8981\u7684\u8ba1\u7b97\u8d44\u6e90\uff0c\u5e76\u901a\u8fc7\u9884\u5360\u7684\u65b9\u5f0f\u8fdb\u884c\u8c03\u914d\uff1b\\n- \u52a8\u6001\u7533\u8bf7\u8d44\u6e90\uff1a\u5f53\u524dworker\u5747\u4e3a\u5e38\u9a7b\u8fdb\u7a0b/\u8282\u70b9\u3002\u52a8\u6001\u7533\u8bf7\u8d44\u6e90\u53ef\u4ee5\u63d0\u9ad8\u5229\u7528\u7387\uff1b\\n- \u66f4\u7ec6\u7c92\u5ea6\u7684\u8d44\u6e90\u9694\u79bb\uff1a\u901a\u8fc7worker group\u6216\u8005\u8fdb\u7a0b\u7ea7\u522b\u7684\u9694\u79bb\uff0c\u51cf\u5c11\u5404query\u4e4b\u95f4\u76f8\u4e92\u5f71\u54cd\uff1b"},{"id":"2023-05-24-byconity-announcement-opensources-its-cloudnative-data-warehouse","metadata":{"permalink":"/zh-cn/blog/2023-05-24-byconity-announcement-opensources-its-cloudnative-data-warehouse","editUrl":"https://github.com/ByConity/byconity.github.io/tree/main/blog/2023-05-24-byconity-announcement-opensources-its-cloudnative-data-warehouse/index.md","source":"@site/blog/2023-05-24-byconity-announcement-opensources-its-cloudnative-data-warehouse/index.md","title":"ByteDance Open Sources Its Cloud Native Data Warehouse ByConity","description":"ByConity is an open-source cloud-native data warehouse developed by ByteDance. It utilizes a computing-storage separation architecture and offers various essential features, including the separation of computing and storage, elastic scalability, tenant resource isolation, and strong consistency in data reading and writing. By leveraging optimizations from popular OLAP engines like column storage, vectorized execution, MPP execution, and query optimization, ByConity delivers exceptional read and write performance.","date":"2023-05-24T00:00:00.000Z","formattedDate":"2023\u5e745\u670824\u65e5","tags":[{"label":"video introduction","permalink":"/zh-cn/blog/tags/video-introduction"},{"label":"docusaurus","permalink":"/zh-cn/blog/tags/docusaurus"}],"readingTime":11.185,"hasTruncateMarker":false,"authors":[{"name":"Vini Jaiswal","title":"ByConity maintainer","url":"https://www.linkedin.com/in/vinijaiswal","imageURL":"https://github.com/vinijaiswal.png","key":"vinijaiswal"}],"frontMatter":{"slug":"2023-05-24-byconity-announcement-opensources-its-cloudnative-data-warehouse","date":"2023-05-24T00:00:00.000Z","title":"ByteDance Open Sources Its Cloud Native Data Warehouse ByConity","authors":["vinijaiswal"],"tags":["video introduction","docusaurus"],"keywords":["ByteDance","datawarehouse","byconity","open source","ByteDance Open Source"]},"prevItem":{"title":"ByConity ELT\u539f\u7406\u8be6\u89e3","permalink":"/zh-cn/blog/byconity-elt"},"nextItem":{"title":"ByConity -- An Open source Cloud-native Data Warehouse","permalink":"/zh-cn/blog/byconity-an-opensource-cloudnative-data-warehouse-post"}},"content":"ByConity is an open-source cloud-native data warehouse developed by ByteDance. It utilizes a computing-storage separation architecture and offers various essential features, including the separation of computing and storage, elastic scalability, tenant resource isolation, and strong consistency in data reading and writing. By leveraging optimizations from popular OLAP engines like column storage, vectorized execution, MPP execution, and query optimization, ByConity delivers exceptional read and write performance.\\n\\n# History of ByConity\\n\\nThe origins of ByConity can be traced back to 2018 when ByteDance initially implemented ClickHouse for internal use. As the business grew, the data volume increased significantly to cater to a large user base. However, ClickHouse\'s Shared-Nothing architecture, where each node operates independently without sharing storage resources, posed certain challenges during its usage. Here are some of the issues encountered:\\n\\n## Expansion and contraction: \\nDue to the tight coupling of computing and storage resources in ClickHouse, scaling the system incurred higher costs and involved data migration. This prevented real-time on-demand scalability, resulting in inefficient resource utilization.\\n\\n## Multi-tenancy and shared cluster environment:\\nClickHouse\'s tightly coupled architecture led to interactions among multiple tenants in a shared cluster environment. Since reading and writing operations were performed on the same node, they often interfered with each other, impacting overall performance.\\n\\n## Performance limitations: \\nClickHouse\'s support for complex queries, such as multi-table join operations, was not optimal, which hindered the system\'s ability to handle such queries efficiently.\\n\\nTo address these pain points, ByteDance undertook an architectural upgrade of ClickHouse. In 2020, we initiated the ByConity project internally. After releasing the Beta version in January 2023, the project was officially made available to the public at the end of May 2023.\\n\\n![Figure 1 ByteDance ClickHouse usage](./f1-byte-clickhouse-usage.png)\\n\\nFigure 1: ByteDance ClickHouse Usage\\n\\n# Features of ByConity\\n\\nByConity implements a computing and storage separation architecture that transforms the original local management of computing and storage on individual nodes. Instead, it adopts a unified management approach for all data across the entire cluster using distributed storage. This transformation results in stateless computing nodes, enabling dynamic expansion and contraction by leveraging the scalability of distributed storage and the stateless nature of computing nodes. ByConity offers several crucial features that enhance its functionality and performance:\\n\\n## Storage-Computing Separation\\n\\nOne of the critical advantages of ByConity is its storage-computing separation architecture, which enables read-write separation and elastic scaling. This architecture ensures that read and write operations do not affect each other, and computing resources and storage resources can be independently expanded and contracted on demand, ensuring efficient resource utilization. ByConity also supports multi-tenant resource isolation, making it suitable for multi-tenant environments.\\n\\n![Figure 2: ByConity storage-computing separation to achieve multi-tenant isolation](./f2-storage-computing-separation.png)\\nFigure 2: ByConity storage-computing separation to achieve multi-tenant isolation\\n\\n## Resource Isolation\\n\\nByConity provides resource isolation, ensuring that different tenants have separate and independent resources. This prevents interference or impact between tenants, promoting data privacy and efficient multi-tenancy support.\\n\\n## Elastic Scaling\\n\\n ByConity supports elastic expansion and contraction, allowing for real-time and on-demand scaling of computing resources. This flexibility ensures efficient resource utilization and enables the system to adapt to changing workload requirements.\\n \\n## Strong Data Consistency\\n\\nByConity ensures strong consistency of data read and write operations. This ensures that data is always up-to-date and eliminates any inconsistencies between read and write operations, guaranteeing data integrity and accuracy.\\n\\n## High Performance\\n\\nByConity incorporates optimization techniques from mainstream OLAP engines, such as column storage, vectorized execution, MPP execution, and query optimization. These optimizations enhance read and write performance, enabling faster and more efficient data processing and analysis.\\n\\n# Technical Architecture of ByConity\\nByConity follows a three-layer architecture consisting of:\\n1. Service access layer: The service access layer, represented by ByConity Server, handles client data and service access. \\n2. Computing layer: The computing layer comprises multiple computing groups, where each Virtual Warehouse (VW) functions as a computing group.  \\n3. Data storage layer: The data storage layer utilizes distributed file systems like HDFS and S3.\\n\\n![Figure 3: ByConity\'s architecture](./f3-three-layer-architecture.png)\\nFigure 3: ByConity\'s architecture\\n\\n# Working Principle of ByConity\\n\\nByConity is a powerful open-source cloud-native data warehouse that adopts a storage-computing separation architecture. In this section, we will examine the working principle of ByConity and the interaction process of each component of ByConity through the complete life cycle of a SQL.\\n\\n![Figure 4: ByConity internal component interaction diagram](./f4-internal-component-interaction.png)\\nFigure 4: ByConity internal component interaction diagram\\n\\nFigure 4 depicts the interaction diagram of ByConity\'s components. In the figure, the dotted line represents the inflow of a SQL query, the double-headed arrow indicates component interaction, and the one-way arrow represents data processing and output to the client. Let\'s explore the interaction process of each component in ByConity throughout the complete lifecycle of a SQL query.\\n\\nByConity\'s working principle can be divided into three stages:\\n\\n## Stage 1: Query Request\\n\\nThe client submits a Query request to the server. The server initially performs **parsing** and subsequently analyzes and optimizes the query through the **Query Analyzer and Optimizer** to generate an efficient executable plan. To access the required **metadata**, which is stored in a distributed key-value (KV) store, ByConity leverages **FoundationDB** and reads the metadata from the **Catalog**.\\n\\n## Stage 2: Plan Scheduling\\n\\nByConity passes the optimized executable plan to the **Plan Scheduler** component. The scheduler accesses the **Resource Manager** to obtain available computing resources and determines which nodes to schedule the query tasks for execution.\\n\\n## Stage 3: Query Execution\\n\\nThe Query request is executed on **ByConity\'s Workers**. The Workers read data from the underlying **Cloud Storage** and perform computations by establishing a Pipeline. The server then aggregates the calculation results from multiple Workers and returns them to the client.\\n\\nAdditionally, ByConity includes two main components: **Time-stamp Oracle** and **Daemon Manager**. The time-stamp oracle supports transaction processing, while the daemon manager manages and schedules subsequent tasks.\\n\\n## Main Component Library\\n\\nTo better understand the working principle of ByConity, let\'s take a look at the main components of ByConity:\\n\\n### Metadata Management\\n\\nByConity offers a highly available and high-performance metadata read and write service called the Catalog Server. It supports complete transaction semantics (ACID). Furthermore, we have designed the Catalog Server with a flexible architecture, allowing for the pluggability of backend storage systems. Currently, we support Apple\'s open-source FoundationDB, and there is potential for extending support to other backend storage systems in the future.\\n\\n### Query Optimizer\\n\\nThe query optimizer plays a crucial role in the performance of a database system. A well-designed optimizer can significantly enhance query performance, particularly in complex query scenarios, where it can achieve performance improvements ranging from several times to hundreds of times. ByConity\'s self-developed optimizer focuses on improving optimization capabilities through two main approaches:\\n- RBO (Rule-Based Optimization): This capability encompasses various optimizations such as column pruning, partition pruning, expression simplification, subquery dissociation, predicate pushdown, redundant operator elimination, Outer-Join to Inner-Join conversion, operator pushdown storage, distributed operator splitting, and other heuristic optimization techniques.\\n- CBO (Cost-Based Optimization): ByConity\'s optimizer also includes cost-based optimization capabilities. This includes support for join reorder, outer-join reorder, join/agg reorder, common table expressions (CTE), materialized views, dynamic filter push-down, magic set optimization, and other cost-based techniques. Additionally, it integrates property enforcement for distributed planning.\\n\\n### Query Scheduling\\n\\nByConity currently supports two query scheduling strategies: Cache-aware scheduling and Resource-aware scheduling.\\n\\n- The **cache-aware scheduling** focuses on scenarios where computing and storage are separated. Its objective is to maximize cache utilization and minimize cold reads. This strategy aims to schedule tasks to nodes that have corresponding data caches, enabling computations to leverage the cache and improve read and write performance. Additionally, considering the dynamic expansion and contraction of the system, cache-aware scheduling strives to minimize the impact of cache failure on query performance when the computing group\'s topology changes.\\n- **Resource-aware scheduling** analyzes the resource usage of different nodes within the computing group across the entire cluster. It performs targeted scheduling to optimize resource utilization. Moreover, resource-aware scheduling incorporates flow control mechanisms to ensure rational resource utilization and prevent negative effects caused by overload, such as system downtime.\\n\\n### Computing Group\\n\\nByConity enables different tenants to utilize distinct computing resources, as depicted in Figure 5. With ByConity\'s architecture, implementing features like multi-tenant isolation and read-write separation becomes straightforward. Each tenant can leverage separate computing groups to achieve multi-tenant isolation and support read-write separation. The computing groups can be dynamically expanded and contracted on-demand, ensuring efficient resource utilization. During periods of low resource utilization, resource sharing can be employed, allowing computing groups to be allocated to other tenants to maximize resource utilization and minimize costs.\\n\\n### Virtual File System\\n\\nThe virtual file system module serves as an intermediary layer for data reading and writing. ByConity has optimized this module to provide a \\"storage as a service\\" capability to other modules. The virtual file system offers a unified file system abstraction, shielding the underlying different back-end implementations. It facilitates easy expansion and supports multiple storage systems, such as HDFS or object storage.\\n\\n### Cache Acceleration\\n\\nByConity utilizes caching to accelerate query processing. Under the computing-storage separation architecture, cache acceleration is performed in both the metadata and data dimensions. In the metadata dimension, ByConity caches Table and Partition information in the memory of the server-side (ByConity Server). In the data dimension, cache acceleration occurs on the Worker side within the computing group. This hierarchical caching mechanism utilizes both memory and disk, with Mark collection serving as the cache granularity. These caching strategies effectively enhance query speed and performance.\\n\\n# How to Deploy Byconity\\n\\nByConity currently supports four acquisition and deployment modes. Community developers are welcome to use them and submit issues to us:\\n- Stand-alone Docker: ByConity provides a Docker deployment option, which can be accessed at https://github.com/ByConity/byconity-docker\\n- K8s cluster deployment: ByConity also supports deployment on Kubernetes clusters. The deployment guide for Kubernetes can be found at https://github.com/ByConity/byconity-deploy\\n- Physical machine deployment: If you prefer to deploy ByConity on physical machines, you can refer to the repository at https://github.com/ByConity/ByConity/tree/master/packages\\n- Source code compilation: You can compile the ByConity source code yourself. The source code repository can be accessed at https://github.com/ByConity/ByConity#build-byconity\\n\\n# ByConity\'s Future Open-Source Plan\\n\\nByConity includes several key milestones in its open-source community roadmap through 2023. These milestones are designed to enhance ByConity\'s functionality, performance, and ease of use. Among them, the development of new storage engines, support for more data types, and integration with other data management tools are some important areas of focus. We have listed the following directions, and created an issue on Github: https://github.com/ByConity/ByConity/issues/26, inviting the community to join us to discuss co-development:\\n\\n- **Performance improvement**: ByConity aims to boost performance through various optimizations. This includes leveraging indexes for acceleration, such as Skip-index optimization, support for new Zorder-index and inverted indexes. ByConity will also focus on the construction and acceleration of external indexes, as well as the automatic recommendation and conversion of indexes. Continuous enhancements to the query optimizer and the implementation of a distributed caching mechanism are also part of the performance improvement efforts.\\n- **Stability improvement**: There are two aspects here.\\n  - One is to support resource isolation in more dimensions. ByConity is committed to improving stability by extending resource isolation capabilities in multiple dimensions, thereby providing better multi-tenant support. \\n  - The second direction is to enrich metrics and improve observability and problem diagnosis capabilities, ensuring a stable and reliable experience for users.\\n- **Enterprise-level feature enhancements**: ByConity aims to introduce finer-grained authority control, improve data security-related functions such as backup, recovery, and data encryption and continue to explore techniques for deep compression of data to save storage costs.\\n- **Ecosystem compatibility improvement**: ByConity plans to expand its compatibility with various storage systems, including popular object storage solutions like S3 and TOS. It plans to enhance the overall compatibility and integration capabilities, facilitating seamless integration with other tools and frameworks. Moreover, it aims to support data lake federation queries, enabling interaction with technologies like Hudi, Iceberg, and more.\\n\\n# Working with the Community\\n\\nSince the release of the Beta version, ByConity has received support from numerous enterprise developers, including Huawei, Electronic Cloud, Zhanxinzhanli, Tianyi Cloud, Vipshop, and Transsion Holdings. These organizations have actively contributed by deploying ByConity in their respective environments, undergoing TPC-DS verification, and conducting tests in their business scenarios. The results have been promising, and their feedback has provided valuable insights for improvement, which we greatly appreciate.\\n\\nWe are delighted to receive the ideas and willingness of community partners to build together. We have already initiated joint development efforts with Huawei Terminal Cloud. Our collaborative endeavors will focus on various areas, such as Kerberos authentication, ORC support, and integration with S3 storage. \\n\\nIf you are interested in joining our community and participating in the development of ByConity, we invite you to visit our GitHub repository at https://github.com/ByConity/ByConity. You can find more information and details about our ongoing projects, contribute your ideas, and collaborate with us to further enhance ByConity. To get involved, simply scan the QR code provided below to join our [Discord](https://discord.gg/V4BvTWGEQJ) or follow us on [Twitter](https://twitter.com/ByConity). \\n\\n![ByConity Discord Group](./f5-ByConity-Discord-QR-Code.jpeg)\\nByConity Discord Group\\n\\n![ByConity Twitter](./f5-ByConity-Twitter-QR-code.jpeg)\\nByConity Twitter\\n\\n\\n# Summary\\n\\nIn summary, ByConity is an open source cloud-native data warehouse that offers features such as read-write separation, elastic expansion and contraction, tenant resource isolation, and strong data read and write consistency. It utilizes a computing-storage separation architecture and leverages optimizations from mainstream OLAP engines to deliver excellent read and write performance. As ByConity continues to evolve and improve, it aims to become a key tool for cloud-native data warehousing in the future."},{"id":"byconity-an-opensource-cloudnative-data-warehouse-post","metadata":{"permalink":"/zh-cn/blog/byconity-an-opensource-cloudnative-data-warehouse-post","editUrl":"https://github.com/ByConity/byconity.github.io/tree/main/blog/2023-04-10-byconity-an-opensource-cloudnative-data-warehouse-post/index.md","source":"@site/blog/2023-04-10-byconity-an-opensource-cloudnative-data-warehouse-post/index.md","title":"ByConity -- An Open source Cloud-native Data Warehouse","description":"Introduction to ByConity","date":"2023-04-10T00:00:00.000Z","formattedDate":"2023\u5e744\u670810\u65e5","tags":[{"label":"video introduction","permalink":"/zh-cn/blog/tags/video-introduction"},{"label":"docusaurus","permalink":"/zh-cn/blog/tags/docusaurus"}],"readingTime":9.78,"hasTruncateMarker":false,"authors":[{"name":"Zhaojie Niu","title":"ByConity maintainer","url":"https://github.com/hustnn","imageURL":"https://github.com/hustnn.png","key":"hustnn"},{"name":"Yunbo Wang","title":"ByConity maintainer","url":"https://github.com/tigerwangyb","imageURL":"https://github.com/tigerwangyb.png","key":"tigerwangyb"}],"frontMatter":{"slug":"byconity-an-opensource-cloudnative-data-warehouse-post","title":"ByConity -- An Open source Cloud-native Data Warehouse","authors":["hustnn","tigerwangyb"],"tags":["video introduction","docusaurus"]},"prevItem":{"title":"ByteDance Open Sources Its Cloud Native Data Warehouse ByConity","permalink":"/zh-cn/blog/2023-05-24-byconity-announcement-opensources-its-cloudnative-data-warehouse"}},"content":"## Introduction to ByConity\\n\\nByConity is an open-source cloud-native data warehouse that adopts a storage-computing separation architecture. It supports several key features, including separation of storage and computing, elastic expansion and contraction, isolation of tenant resources, and strong consistency of data read and write. By utilizing mainstream OLAP engine optimizations, such as column storage, vectorized execution, MPP execution, query optimization, etc., ByConity can provide excellent read and write performance.\\n\\n## ByConity\'s History\\n\\nThe background of ByConity can be traced back to 2018 when ByteDance began to use ClickHouse internally. Due to the development of business, the scale of data has become larger and larger to serve a large number of users. However, because ClickHouse is a Shared-Nothing architecture, each node is independent and does not share storage resources, so computing resources and storage resources are tightly coupled. This leads to a higher cost of expansion and contraction, and involves data migration, which prevents real-time and on-demand expansion and contraction, resulting in a waste of resources. Furthermore, the tightly coupled architecture of ClickHouse will cause multi-tenants to interact with each other in the shared cluster. In addition, because reading and writing are completed on one node, reading and writing are affected. Finally, ClickHouse does not support performance in complex queries such as multi-table join. Based on these pain points, the ByConity project was launched in January 2020.\\n\\nThe ByConity team hopes to give the project back to the community and improve it through the power of open source. In January 2023, ByConity was officially open-sourced, and the beta version was released.\\n\\n![Figure 1 ByteDance ClickHouse usage](./f1-byte-clickhouse-usage.png)\\n\\nFigure 1: ByteDance ClickHouse Usage\\n\\n# Features of ByConity\\n\\nByConity has several key features that make it a powerful open-source cloud-native data warehouse.\\n\\n## Storage-Computing Separation\\n\\nOne of the critical advantages of ByConity is its storage-computing separation architecture, which enables read-write separation and elastic scaling. This architecture ensures that read and write operations do not affect each other, and computing resources and storage resources can be independently expanded and contracted on demand, ensuring efficient resource utilization. ByConity also supports multi-tenant resource isolation, making it suitable for multi-tenant environments.\\n\\n![Figure 2: ByConity storage-computing separation to achieve multi-tenant isolation](./f2-storage-computing-separation.png)\\nFigure 2: ByConity storage-computing separation to achieve multi-tenant isolation\\n\\n## Elastic Scaling\\n\\nByConity supports flexible expansion and contraction, enabling real-time and on-demand expansion and contraction of computing resources, ensuring efficient use of resources.\\n\\n## Resource Isolation\\n\\nByConity isolates the resources of different tenants, ensuring that tenants are not affected by each other.\\n\\n## Strong Data Consistency\\n\\nByConity ensures strong consistency of data read and write, ensuring that data is always up to date with no inconsistencies between reads and writes.\\n\\n## High Performance\\n\\nByConity adopts mainstream OLAP engine optimizations, such as column storage, vectorized execution, MPP execution, query optimization, etc., ensuring excellent read and write performance.\\n\\n# ByConity\'s Technical Architecture\\n\\nByConity\'s architecture is divided into three layers:\\n\\n1. Service access layer: Responsible for client data and service access, i.e., ByConity Server\\n2. Computing group: ByConity\'s computing resource layer, where each Virtual Warehouse is a computing group\\n3. Data storage: Distributed file system, such as HDFS, S3, etc.\\n\\n![Figure 3: ByConity\'s architecture](./f3-three-layer-architecture.png)\\nFigure 3: ByConity\'s architecture\\n\\n# Working Principle of ByConity\\n\\nByConity is a powerful open-source cloud-native data warehouse that adopts a storage-computing separation architecture. In this section, we will examine the working principle of ByConity and the interaction process of each component of ByConity through the complete life cycle of a SQL.\\n\\n![Figure 4: ByConity internal component interaction diagram](./f4-internal-component-interaction.png)\\nFigure 4: ByConity internal component interaction diagram\\n\\nFigure 4 above is the interaction diagram of ByConity components. The dotted line in the figure indicates the inflow of a SQL, the two-way arrow in the solid line indicates the interaction within the component, and the one-way arrow indicates the data processing and output to the client.\\n\\nByConity\'s working principle can be divided into three stages:\\n\\n## Stage 1: Query Request\\n\\nThe client submits a query request to the server, and the server first performs parsing, then analyzes and optimizes through analyzer and optimizer to generate a more efficient executable plan. Here, metadata MetaData is read, which is stored in a distributed KV. ByConity uses FoundationDB and reads the metadata through the Catalog.\\n\\n## Stage 2: Plan Scheduling\\n\\nByConity submits the executable plan generated by the analysis and optimizer to the scheduler (Plan Scheduler). The scheduler obtains idle computing resources by accessing the resource manager and decides which nodes to schedule query tasks for execution.\\n\\n## Stage 3: Query Execution\\n\\nQuery requests are finally executed on ByConity\'s Worker, and the Worker will read data from the lowest-level Cloud storage and perform calculations by establishing a pipeline. Finally, the calculation results of multiple workers are aggregated by the server and returned to the client.\\n\\nIn addition to the above components, ByConity also has two main components, Time-stamp Oracle and Deamon Manager. The former ByConity supports transaction processing, and the latter manages and schedules some subsequent tasks.\\n\\n# Main Component Library\\n\\nTo better understand the working principle of ByConity, let\'s take a look at the main components of ByConity:\\n\\n## Metadata Management\\n\\nByConity provides a highly available and high-performance metadata read and write service - Catalog Server. And ByConity supports complete transaction semantics (ACID). At the same time, we have made a better abstraction of the Catalog Server, making the back-end storage system pluggable. Currently, we support Apple\'s open-source FoundationDB, which can be expanded to support more back-end storage systems later.\\n\\n## Query Optimizer\\n\\nThe query optimizer is one of the cores of the database system. A good optimizer can greatly improve query performance. ByConity\'s self-developed optimizer improves optimization capabilities based on two directions:\\n\\n- RBO: Rule-Based Optimization capability. Support: column pruning, partition pruning, expression simplification, subquery disassociation, predicate pushdown, redundant operator elimination, outer-JOIN to INNER-JOIN, operator pushdown storage, distributed operator splitting, etc.\\n- CBO: Cost-Based Optimization capability. Support: Join Reorder, Outer-Join Reorder, Join/Agg Reorder, CTE, Materialized View, Dynamic Filter Push-Down, Magic Set, and other cost-based optimization capabilities. And integrate Property Enforcement for distributed planning.\\n\\n## Query Scheduling\\n\\nByConity currently supports two query scheduling strategies: Cache-aware scheduling and Resource-aware scheduling.\\n\\n- The cache-aware scheduling policy is aimed at scenarios where storage and computing are separated, aiming to maximize the use of the cache and avoid cold reads. The cache-aware scheduling strategy will try to schedule tasks to nodes with corresponding data caches, so that calculations can hit the cache and improve read and write performance.\\n- Resource-aware scheduling perceives the resource usage of different nodes in the computing group in the entire cluster and performs targeted scheduling to maximize resource utilization. At the same time, it also performs flow control to ensure reasonable use of resources and avoid negative effects caused by overload, such as system downtime.\\n\\n## Computing Group\\n\\nByConity supports different tenants to use different computing resources. Under ByConity\'s new architecture, it is easy to implement features such as multi-tenant isolation and read-write separation. Different tenants can use different computing groups to achieve multi-tenant isolation and support read-write separation. Due to the convenient expansion and contraction, the computing group can be dynamically expanded and contracted on demand to ensure efficient resource utilization. When resource utilization is not high, resource sharing can be carried out, and computing groups can be seconded to other tenants to maximize resource utilization and reduce costs.\\n\\n## Virtual File System\\n\\nThe virtual file system module is used as the middle layer of data reading and writing. ByConity has made a better package, exposing storage as a service to other modules to realize \\"storage as a service\\". The virtual file system provides a unified file system abstraction, shields different back-end implementations, facilitates expansion, and supports multiple storage systems, such as HDFS or object storage.\\n\\n## Cache Acceleration\\n\\nByConity performs query acceleration through caching. Under the architecture of separating storage and computing, ByConity performs cache acceleration in both metadata and data dimensions. In the metadata dimension, by caching in the memory of ByConity\'s Server side, table, and partition are used as granularity. In the data dimension, ByConity\'s Worker side, that is, the computing group, is used for caching, and the cache on the Worker side is hierarchical. At the same time, memory and disk are used, and the mark set is used as the cache granularity, thereby effectively improving the query speed.\\n\\n## How to Obtain and Deploy\\n\\nByConity currently supports four acquisition and deployment modes. Community developers are welcome to use them and submit issues to us:\\n\\n- Stand-alone version\\n  - Use docker compose to pull up Reference: https://github.com/ByConity/byconity-docker\\n- K8s cluster version mode\\n  - Use K8s deployment reference: https://github.com/ByConity/byconity-deploy\\n- Physical machine deployment mode\\n  - Deploy on a physical machine using the package manager: https://github.com/ByConity/ByConity/tree/master/packages\\n- Source code compilation method\\n  - Reference: https://github.com/ByConity/ByConity#build-byconity\\n\\n## ByConity\'s Future Open-Source Plan\\n\\nByConity includes several key milestones in its open-source community roadmap through 2023. These milestones are designed to enhance ByConity\'s functionality, performance, and ease of use. Among them, the development of new storage engines, support for more data types, and integration with other data management tools are some important areas of focus. We have listed the following directions, and we have created an issue on Github: https://github.com/ByConity/ByConity/issues/26, inviting community partners to join us to discuss co-construction:\\n\\n- In terms of performance improvement: ByConity hopes to continue to improve performance, and here are three technical directions. One is to use indexes for acceleration, which includes four aspects:\\n  - Optimize the existing skip index;\\n  - Explore the implementation of new index research, such as zorder-index and inverted index;\\n  - ByConity builds and accelerates Hive table indexes\\n  - Index recommendation and conversion, lowering the threshold for users to use\\n    The second is the continuous optimization of the query optimizer; the third is that ByConity\'s cache mechanism is local, and each computing group can only access its own cache. In the future, it is hoped to implement a distributed cache mechanism to further improve the cache hit rate.\\n- Stability improvement: There are two aspects here. One is to support resource isolation in more dimensions. Currently, it only supports resource isolation in the computing group dimension. In the next step, resource isolation will also be supported on the server side, providing better end-to-end Guaranteed multi-tenancy capability. The second direction is to enrich metrics and improve observability and problem diagnosis capabilities.\\n- Enterprise-level feature enhancements: We hope to achieve more detailed permission control, including column-level permission control. The other is to improve the functions related to data security, such as data backup and recovery and data end-to-end encryption. Finally, we continue to explore the deep compression of data to save storage costs.\\n- Ecological compatibility improvement: This direction is the most important point. ByConity plans to support more types of storage backends, such as AWS\'s S3, Volcano Engine\'s object storage, etc. In terms of improving ecological compatibility, it includes integration with some drivers and some open source software. At the same time, we also hope to support federated queries of data lakes, such as Hudi, Iceberg, etc.\\n\\nIn short, ByConity is an open source cloud-native data warehouse that provides read-write separation, elastic expansion and contraction, tenant resource isolation, and strong consistency of data read and write. Its storage-computing separation architecture, combined with mainstream OLAP engine optimization, ensures excellent read and write performance. As ByConity continues to develop and improve, it is expected to become an important tool for cloud-native data warehouses in the future.\\n\\nWe have a video that introduces ByConity in detail, including a demo of ByConity. If you need more information, you can check the following link: https://www.bilibili.com/video/BV15k4y1b7pw/?spm_id_from=333.999.0.0&vd_source=71f3be2102fec1a0171b49a530cefad0\\n\\nScan the QR code to reply [name + QR code] Join the ByConity communication group to get more project dynamics and activity information.\\n\\n![ByConity Community QR Code](./f5-byconity-community-qrcode.png)\\nByConity Community QR Code"}]}')}}]);