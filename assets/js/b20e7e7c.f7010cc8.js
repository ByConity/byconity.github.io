"use strict";(self.webpackChunkbyconity=self.webpackChunkbyconity||[]).push([[1588],{49613:(e,t,a)=>{a.d(t,{Zo:()=>d,kt:()=>f});var n=a(59496);function o(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function i(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function r(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?i(Object(a),!0).forEach((function(t){o(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):i(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function l(e,t){if(null==e)return{};var a,n,o=function(e,t){if(null==e)return{};var a,n,o={},i=Object.keys(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||(o[a]=e[a]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(o[a]=e[a])}return o}var s=n.createContext({}),c=function(e){var t=n.useContext(s),a=t;return e&&(a="function"==typeof e?e(t):r(r({},t),e)),a},d=function(e){var t=c(e.components);return n.createElement(s.Provider,{value:t},e.children)},u="mdxType",p={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},m=n.forwardRef((function(e,t){var a=e.components,o=e.mdxType,i=e.originalType,s=e.parentName,d=l(e,["components","mdxType","originalType","parentName"]),u=c(a),m=o,f=u["".concat(s,".").concat(m)]||u[m]||p[m]||i;return a?n.createElement(f,r(r({ref:t},d),{},{components:a})):n.createElement(f,r({ref:t},d))}));function f(e,t){var a=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var i=a.length,r=new Array(i);r[0]=m;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l[u]="string"==typeof e?e:o,r[1]=l;for(var c=2;c<i;c++)r[c]=a[c];return n.createElement.apply(null,r)}return n.createElement.apply(null,a)}m.displayName="MDXCreateElement"},87662:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>s,contentTitle:()=>r,default:()=>p,frontMatter:()=>i,metadata:()=>l,toc:()=>c});var n=a(64778),o=(a(59496),a(49613));const i={title:"Column Storage Design Principles",tags:["Docs"]},r="Column storage design principle",l={unversionedId:"advanced-guide/column-based-storage",id:"version-0.2.0/advanced-guide/column-based-storage",title:"Column Storage Design Principles",description:"Typically, transactional databases use row storage to support transactions and high concurrent reading and writing, while analytical databases use column storage to reduce IO and facilitate compression. ByConity, on the other hand, uses column storage to ensure read and write performance, support transaction consistency, and is well-suited for large-scale data calculations.",source:"@site/versioned_docs/version-0.2.0/advanced-guide/column-based-storage.mdx",sourceDirName:"advanced-guide",slug:"/advanced-guide/column-based-storage",permalink:"/docs/0.2.0/advanced-guide/column-based-storage",draft:!1,editUrl:"https://github.com/ByConity/byconity.github.io/tree/main/versioned_docs/version-0.2.0/advanced-guide/column-based-storage.mdx",tags:[{label:"Docs",permalink:"/docs/0.2.0/tags/docs"}],version:"0.2.0",frontMatter:{title:"Column Storage Design Principles",tags:["Docs"]},sidebar:"tutorialSidebar",previous:{title:"Bucket table best practice manual",permalink:"/docs/0.2.0/advanced-guide/bucket-table-best-practice"},next:{title:"Complex Query Models and Execution Tuning",permalink:"/docs/0.2.0/advanced-guide/complex-query-model-and-optimisation"}},s={},c=[{value:"Data Layout",id:"data-layout",level:3},{value:"Part Delta",id:"part-delta",level:3},{value:"Part file content",id:"part-file-content",level:3},{value:"Compaction",id:"compaction",level:3}],d={toc:c},u="wrapper";function p(e){let{components:t,...a}=e;return(0,o.kt)(u,(0,n.Z)({},d,a,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"column-storage-design-principle"},"Column storage design principle"),(0,o.kt)("p",null,"Typically, transactional databases use row storage to support transactions and high concurrent reading and writing, while analytical databases use column storage to reduce IO and facilitate compression. ByConity, on the other hand, uses column storage to ensure read and write performance, support transaction consistency, and is well-suited for large-scale data calculations."),(0,o.kt)("h3",{id:"data-layout"},"Data Layout"),(0,o.kt)("p",null,"Table data is physically divided into multiple parts based on the partition key and stored in a unified distributed file system and cloud storage logical storage path. The size of each part is limited by the amount of data and the number of rows. The computing group is allocated parts based on the service node strategies (pre-allocation and real-time allocation) to obtain their corresponding parts."),(0,o.kt)("h3",{id:"part-delta"},"Part Delta"),(0,o.kt)("p",null,"After the initial construction of Part data, it is a Part data file with row and column mixed storage. With the construction of DML/data dictionary/Bitmap index, etc., Part has incremental data. This part of data can be stored in the following two ways:"),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},"Every build will Rewrite Part data"),(0,o.kt)("li",{parentName:"ol"},"Generate incremental data and asynchronously merge it into a large Part file in the background")),(0,o.kt)("p",null,"The solution may have a certain impact on the availability of the entire cluster:"),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},"Every construction of DML/data dictionary may involve a full amount of IO operations on the entire table Parts, which is relatively expensive."),(0,o.kt)("li",{parentName:"ol"},"It takes a long time to build DML and other operations will take a long time to complete, which is not friendly to users. We adopt the second solution.")),(0,o.kt)("h3",{id:"part-file-content"},"Part file content"),(0,o.kt)("p",null,"The part data is divided into two parts:"),(0,o.kt)("p",null,"One is that the whole Part includes meta-information such as rows/schema/column data in the data file, such as Offset, which is stored persistently and cached by computing nodes"),(0,o.kt)("p",null,"The second is the actual data information, this part of the information includes the actual column bin data/column mrk data/Map key bin/Map key index/data dictionary data/bitmap index data, etc., the data is in the data of the Part according to the Offset information in the meta information Files are stored sequentially."),(0,o.kt)("h3",{id:"compaction"},"Compaction"),(0,o.kt)("p",null,"ByConity supports splitting a Part file into multiple smaller files. The maximum size and maximum number of lines of a Part can be configured, and the resulting Parts after compaction must meet these limits."),(0,o.kt)("p",null,"The compaction in ByConity is done globally, which is consistent with the previously raised global block ID."))}p.isMDXComponent=!0}}]);