"use strict";(self.webpackChunkbyconity=self.webpackChunkbyconity||[]).push([[515],{49613:(e,t,a)=>{a.d(t,{Zo:()=>u,kt:()=>m});var r=a(59496);function n(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function o(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,r)}return a}function i(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?o(Object(a),!0).forEach((function(t){n(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):o(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function s(e,t){if(null==e)return{};var a,r,n=function(e,t){if(null==e)return{};var a,r,n={},o=Object.keys(e);for(r=0;r<o.length;r++)a=o[r],t.indexOf(a)>=0||(n[a]=e[a]);return n}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(r=0;r<o.length;r++)a=o[r],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(n[a]=e[a])}return n}var c=r.createContext({}),d=function(e){var t=r.useContext(c),a=t;return e&&(a="function"==typeof e?e(t):i(i({},t),e)),a},u=function(e){var t=d(e.components);return r.createElement(c.Provider,{value:t},e.children)},l="mdxType",p={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},h=r.forwardRef((function(e,t){var a=e.components,n=e.mdxType,o=e.originalType,c=e.parentName,u=s(e,["components","mdxType","originalType","parentName"]),l=d(a),h=n,m=l["".concat(c,".").concat(h)]||l[h]||p[h]||o;return a?r.createElement(m,i(i({ref:t},u),{},{components:a})):r.createElement(m,i({ref:t},u))}));function m(e,t){var a=arguments,n=t&&t.mdxType;if("string"==typeof e||n){var o=a.length,i=new Array(o);i[0]=h;var s={};for(var c in t)hasOwnProperty.call(t,c)&&(s[c]=t[c]);s.originalType=e,s[l]="string"==typeof e?e:n,i[1]=s;for(var d=2;d<o;d++)i[d]=a[d];return r.createElement.apply(null,i)}return r.createElement.apply(null,a)}h.displayName="MDXCreateElement"},8713:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>c,contentTitle:()=>i,default:()=>p,frontMatter:()=>o,metadata:()=>s,toc:()=>d});var r=a(64778),n=(a(59496),a(49613));const o={title:"Background and Technical Architecture",sidebar_position:2,tags:["Docs"]},i="Background and technical architecture",s={unversionedId:"introduction/background-and-technical-architecture",id:"version-0.2.0/introduction/background-and-technical-architecture",title:"Background and Technical Architecture",description:"ByConity is an open source Data Warehouse system designed for modern IT architecture changes and, it is designed with a Cloud Native architecture. It provides excellent query and write performance while meeting the needs of Data Warehouse users for resource elastic volume expansion and contraction, read and write separation, resource isolation, and strong data consistency.",source:"@site/versioned_docs/version-0.2.0/introduction/background-and-technical-architecture.mdx",sourceDirName:"introduction",slug:"/introduction/background-and-technical-architecture",permalink:"/docs/0.2.0/introduction/background-and-technical-architecture",draft:!1,editUrl:"https://github.com/ByConity/byconity.github.io/tree/main/versioned_docs/version-0.2.0/introduction/background-and-technical-architecture.mdx",tags:[{label:"Docs",permalink:"/docs/0.2.0/tags/docs"}],version:"0.2.0",sidebarPosition:2,frontMatter:{title:"Background and Technical Architecture",sidebar_position:2,tags:["Docs"]},sidebar:"tutorialSidebar",previous:{title:"Main Principles Concepts",permalink:"/docs/0.2.0/introduction/main-principle-concepts"},next:{title:"Recommended Use Cases",permalink:"/docs/0.2.0/introduction/recommended-use-case"}},c={},d=[{value:"Service Access Layer",id:"service-access-layer",level:2},{value:"Computing Layer",id:"computing-layer",level:2},{value:"Data Storage Layer",id:"data-storage-layer",level:2},{value:"Metadata Storage",id:"metadata-storage",level:3},{value:"Data storage",id:"data-storage",level:3}],u={toc:d},l="wrapper";function p(e){let{components:t,...o}=e;return(0,n.kt)(l,(0,r.Z)({},u,o,{components:t,mdxType:"MDXLayout"}),(0,n.kt)("h1",{id:"background-and-technical-architecture"},"Background and technical architecture"),(0,n.kt)("h1",{id:"background"},"Background"),(0,n.kt)("p",null,"ByConity is an open source Data Warehouse system designed for modern IT architecture changes and, it is designed with a Cloud Native architecture. It provides excellent query and write performance while meeting the needs of Data Warehouse users for resource elastic volume expansion and contraction, read and write separation, resource isolation, and strong data consistency."),(0,n.kt)("p",null,"ByConity uses a large number of mature OLAP technologies, such as column storage engine, MPP execution, intelligent query optimization, vectorization execution, Codegen, indexing, and data compression. It also makes technical innovations for the particularity of cloud scenarios and storage and calculation separation architectures."),(0,n.kt)("h1",{id:"overall-architecture"},"Overall architecture"),(0,n.kt)("p",null,"ByConity can be roughly divided into 3 layers: Service Access Layer, Computing Layer and Storage Layer. The service Access Layer responds to user queries, the computing layer is responsible for computing data, and the storage layer stores user data."),(0,n.kt)("p",null,(0,n.kt)("img",{src:a(35093).Z,width:"2148",height:"2032"})),(0,n.kt)("h2",{id:"service-access-layer"},"Service Access Layer"),(0,n.kt)("p",null,"ByConity's service access layer accepts the user's query, first parses the query, and combines the catalog API to obtain Metadata information to generate an efficient execution plan, then obtains available computing resources through the Resource Manager, and finally schedules the query plan to a suitable (e.g., with cache) computing node for execution. The service access layer consists of one or more servers and supports horizontal expansion, serving as a response to user services and coordinating scheduling. In addition to user jobs, there are background tasks in ByConity, such as compaction/ gc , etc. These background tasks are managed by the Daemon manager and dispatched to the corresponding server for execution."),(0,n.kt)("p",null,"The query optimizer is one of the cores of the ByConity system. An excellent optimizer can greatly improve query performance. Especially in complex query scenarios, the optimizer can improve performance by several to hundreds of times. ByConity's self-developed optimizer provides extreme optimization capabilities based on four major optimization directions (rule-based, cost-based, data-dependence-based, and histroy-based)."),(0,n.kt)("h2",{id:"computing-layer"},"Computing Layer"),(0,n.kt)("p",null,"ByConity's computing layer consists of one or more Virtual Warehouse, and different tenants can use different Virtual Warehouse to achieve physical resource isolation. Resource Manager is responsible for unified management and scheduling of computing resources, and can collect performance data and resource usage of each Virtual Warehouse, dynamically allocate resources for query, write and background tasks, and perform dynamic volume expansion and contraction to improve resource utilization rate."),(0,n.kt)("p",null,"A Virtual Warehouse consists of multiple workers. After each node receives the PlanSegment, it starts to drive the execution of the PlanSegment. The PlanSegment containing the data source starts to read the data, and distributes the data to each downstream node according to certain shuffle rules. The PlanSegment containing exchange input waits for the upstream data. If there is a need to continue shuffle, it will continue to send the data to each node. After multiple rounds of stages are completed, the results will be returned to the server level."),(0,n.kt)("h2",{id:"data-storage-layer"},"Data Storage Layer"),(0,n.kt)("p",null,"ByConity's metadata and data are stored separately. Metadata is stored in a distributed key-value store, and data is stored in a distributed file system or object store ."),(0,n.kt)("h3",{id:"metadata-storage"},"Metadata Storage"),(0,n.kt)("p",null,"ByConity's Metadata storage implements a common catalog API based on a high-performance distributed key-value store (FoundationDB), making the backend pluggable and easy to expand and adapt to other key-value stores. ByConity also implements complete transaction semantics ( ACID ) support on the upper layer of the catalog API, providing efficient and reliable Metadata services and ensuring high data quality."),(0,n.kt)("h3",{id:"data-storage"},"Data storage"),(0,n.kt)("p",null,"ByConity uses cloud storage services such as HDFS or S3 as the data storage layer to store actual data, indexes, etc. The data files of the data table are stored in the remote unified distributed storage system and are separated from the computing nodes. ByConity implements a common layer of virtual file system API on top of the remote distributed storage system, which is convenient for the underlying expansion and adaptation to different storage backends, such as HDFS, Amazon S3, Google cloud storage, Azure blob storage, Alibaba Cloud object storage and so on."),(0,n.kt)("p",null,"Similar to mainstream analytical data, ByConity adopts a columnar storage format to reduce unnecessary data IO to improve query performance, and efficiently compress data to reduce storage costs. In addition, for continuously stored columnar data, ByConity further improves query performance through vectorized execution technology."))}p.isMDXComponent=!0},35093:(e,t,a)=>{a.d(t,{Z:()=>r});const r=a.p+"assets/images/boxcnb2OyIV70Plb6Nrx6Fyc1Sc-0ccafc19db764b56b10032d5442c6b7d.png"}}]);